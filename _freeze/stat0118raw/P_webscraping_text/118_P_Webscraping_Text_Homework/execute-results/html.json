{
  "hash": "d27df59daef559f4b0e262e4be075983",
  "result": {
    "markdown": "---\ntitle: \"STAT 118: Homework P\"\nsubtitle: 'Webscraping Text with `rvest`'\nauthor: \"YOUR NAME HERE\"\nformat:\n  html: \n    toc: true\n    code-overflow: wrap\n    code-fold: true\n    embed-resources: true\n---\n\n::: {.cell}\n\n```{.r .cell-code}\n#make sure the package is installed on your computer or this won't run! \nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n:::\n\n\n\n# 1. \nThe following problems will involve scraping data from [https://www.scrapethissite.com/pages/simple/](https://www.scrapethissite.com/pages/simple/). \n\n\n## a) \nscrape the names of all the countries *Hint: use .country-name*\n\n\n::: {.cell}\n\n:::\n\n\n\n## b) \nScrape the names of each country's capital. *Hint: use .country-capital* \n\n\n::: {.cell}\n\n:::\n\n\n## c) \nScrape the population of each country. No hints this time. \n\n\n::: {.cell}\n\n:::\n\n\n## d) \nScrape the area of each country. No hints this time. \n\n\n::: {.cell}\n\n:::\n\n\n## e) \nCombine the information you've scraped in a) - d) and combine it together into one dataframe called `countries`. Give each of the columns appropriate names.\n\n\n::: {.cell}\n\n:::\n\n\n## f) \nCreate a new column called `Density` in the dataframe `countries` which contains the population density of each country. *Hint: Population Density is calculated as Population divided by area*\n\n\n::: {.cell}\n\n:::\n\n\n## g) \nCreate a barplot which displays the top 10 countries with the highest population density. Be sure you axes are appropriately labeled. \n\n\n::: {.cell}\n\n:::\n\n\n# 2. \nConsider three famous cases which helped to define data privacy and data regulation around webscraping in the US. \n\n- [eBay vs. Bidder's Edge (2000)](https://en.wikipedia.org/wiki/EBay_v._Bidder's_Edge#Order)\n- [Facebook vs. Power Venures (2009)](https://en.wikipedia.org/wiki/Facebook,_Inc._v._Power_Ventures,_Inc.#Ruling) \n- [Linkedin vs. hiQ Labs (2019)](https://en.wikipedia.org/wiki/HiQ_Labs_v._LinkedIn)\n\nChoose ONE of the above case studies to read about on Wikipedia and elsewhere. If you read elsewhere, include a link or citation at the end of this assignment. \n\n*Keep in mind that I am not expecting you to totally understand all the details about this case from a legal perspective. I am asking that you read about these cases and think about the implications of them as both a consumer and a potential data scientist.* \n\n## a) \nWho is the plantiff (The party that brought the legal action)? \n\n\n## b) \nWho is the defendent (The party that is being sued)? \n\n\n## c) \nThe defendent was webscraping. Briefly describe what data they were webscraping and what they did with that data (1-4 sentences or bullet points).  \n\n\n## d) \nIn your personal opinion, was the webscraping harmful to the business of the plantiff? (1-4 sentences or bullet points) *There is no right answer here. Your opinion may be different than the official ruling. Keep in mind that any harm you allege may or may not rise to the level harm which requires financial compensation -- I'm not asking you to make that determination*\n\n## e) \nIf some of your **public** information had been webscraped (ie. your public profile, your public sale, etc), how would you feel about that information being webscraped and being used for the purpose that the defendant used it for? (1-4 sentences or bullet points) *There is no right answer here. This is your personal opinion.*\n\n# Sources\nIf you looked at any information other than the Wikipedia link above, include either web links or citations here. \n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}