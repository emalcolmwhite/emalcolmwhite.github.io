{
  "hash": "4743391731e607604a4187a45206e2c3",
  "result": {
    "markdown": "---\ntitle: 'Cleaning and tidying data using `janitor`'\nauthor: 'Emily Malcolm-White'\nformat:\n  html: \n    toc: TRUE\n    code-overflow: wrap\n    embed-resources: true\n    code-tools:\n      source: true\n      toggle: false\n      caption: none\n    code-annotations: hover\n  pdf: default\nexecute: \n  message: FALSE\n  warning: FALSE\n---\n\n\n\n`janitor` helps clean data quickly and consistently.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(janitor)\n```\n:::\n\n\n\nHere is some messy data to start: \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- read.csv(\"data/messy_student_survey.csv\")\n```\n:::\n\n\n\n# Clean column names with `clean_names()`\n\nclean_names():\n\n- Converts all column names to snake_case\n- Removes special characters and extra spaces\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- data %>% \n  clean_names()\n\nnames(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"student_name\"            \"year_level\"             \n[3] \"major\"                   \"gpa\"                    \n[5] \"favorite_color\"          \"likes_r\"                \n[7] \"hometown\"                \"time_spent_studying_hrs\"\n[9] \"x\"                      \n```\n:::\n:::\n\n\n\n\n# Remove empty rows or columns with remove_empty()\n\nExcel files often include blank rows or columns that sneak into your dataset. Cleaning them helps avoid weird bugs. This doesn't happen so often with .csv files. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- data %>% \n  remove_empty(\"rows\") %>% \n  remove_empty(\"cols\")\n```\n:::\n\n\n\n# Missing data NA\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n**Be explicit about your choices with NAs**\nDonâ€™t just drop them silentlyâ€”use `drop_na()` or `replace_na()`. If you choose to drop missing rows, you need to explain why.\n\n#  Identify duplicate rows with `get_dupes()`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata %>% \n  get_dupes()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   student_name  year_level       major  gpa favorite_color   likes_r hometown\n1                                         NA                                  \n2                                         NA                                  \n3                                         NA                                  \n4                                         NA                                  \n5                                         NA                                  \n6   Student_105 Fourth Year     Biology 3.93            Red        No    Other\n7   Student_105 Fourth Year     Biology 3.93            Red        No    Other\n8   Student_125 Fourth Year  Statistics 2.33           None Sometimes       LA\n9   Student_125 Fourth Year  Statistics 2.33           None Sometimes       LA\n10  Student_156  Third Year Undeclared  2.39           Blue       Yes New York\n11  Student_156  Third Year Undeclared  2.39           Blue       Yes New York\n12  Student_362  First Year     Biology 3.23           Blue Sometimes       LA\n13  Student_362  First Year     Biology 3.23           Blue Sometimes       LA\n14  Student_375  Third Year     Biology 3.35           None Sometimes       LA\n15  Student_375  Third Year     Biology 3.35           None Sometimes       LA\n16  Student_378  First Year  Statistics 2.58            Red        No  Chicago\n17  Student_378  First Year  Statistics 2.58            Red        No  Chicago\n18  Student_395 Second Year Undeclared  2.13            Red Sometimes New York\n19  Student_395 Second Year Undeclared  2.13            Red Sometimes New York\n20  Student_451  First Year     Biology 3.37          Green       Yes New York\n21  Student_451  First Year     Biology 3.37          Green       Yes New York\n22   Student_69 Fourth Year     Biology 2.37         Purple Sometimes  Chicago\n23   Student_69 Fourth Year     Biology 2.37         Purple Sometimes  Chicago\n24   Student_74 Fourth Year  Statistics 3.70          Green        No  Chicago\n25   Student_74 Fourth Year  Statistics 3.70          Green        No  Chicago\n   time_spent_studying_hrs dupe_count\n1                       NA          5\n2                       NA          5\n3                       NA          5\n4                       NA          5\n5                       NA          5\n6                       10          2\n7                       10          2\n8                       11          2\n9                       11          2\n10                       9          2\n11                       9          2\n12                      11          2\n13                      11          2\n14                       8          2\n15                       8          2\n16                      10          2\n17                      10          2\n18                      16          2\n19                      16          2\n20                      10          2\n21                      10          2\n22                      13          2\n23                      13          2\n24                       8          2\n25                       8          2\n```\n:::\n:::\n\n\n\n\n:::{.callout-note}\n\n| Function     | Purpose                                | Output                                          |\n|--------------|----------------------------------------|-------------------------------------------------|\n| `get_dupes()`| Find and display duplicated rows       | Only the duplicated rows (plus a `dupe_count`)  |\n| `distinct()` | Remove duplicates (keep unique rows only) | A cleaned dataset with no duplicates         |\n\n:::\n\nIn this case, it looks appropriate to drop all the duplicated rows (since the student_id is being repeated)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- data %>% \n  distinct()\n```\n:::\n\n\n\n\n# `tably`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata %>% \n  tabyl(year_level) %>% \n  adorn_totals(\"row\") %>%  \n  adorn_percentages(\"col\") %>%  \n  adorn_pct_formatting()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  year_level   n percent\n             0.0    0.2%\n  First Year 0.3   26.3%\n Fourth Year 0.2   24.0%\n Second Year 0.2   24.8%\n  Third Year 0.2   24.8%\n       Total 1.0  100.0%\n```\n:::\n:::\n\n\n\n\nðŸ§  Tips janitor would approve of\n\n- Clean first â†’ Analyze second\n(clean_names(), remove_empty(), get_dupes() first)\n\n",
    "supporting": [
      "118_janitor_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}