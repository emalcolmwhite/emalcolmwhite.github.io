roster <- read_excel("https://github.com/sfirke/janitor/raw/refs/heads/main/dirty_data.xlsx")
raw_roster <- read_excel("data/raw_roster.xlsx")
raw_roster <- read_excel("data/raw_roster.xlsx")
View(raw_roster)
roster <- roster_raw %>%
row_to_names(row_number = 1)
roster_raw <- read_excel("data/raw_roster.xlsx")
roster <- roster_raw %>%
row_to_names(row_number = 1)
roster <- roster_raw %>%
row_to_names(row_number = 1) %>%
clean_names()
roster <- roster_raw %>%
row_to_names(row_number = 1) %>%
clean_names()
View(roster)
roster_raw <- read_excel("data/raw_roster.xlsx")
View(raw_roster)
roster <- roster_raw %>%
row_to_names(row_number = 1) %>%
clean_names()
roster <- roster_raw %>%
row_to_names(row_number = 1) %>%
clean_names()
View(roster)
roster <- roster %>%
select(-do_not_edit)
roster <- roster %>%
remove_empty("rows") %>%
remove_empty("cols")
roster %>%
get_dupes()
roster %>%
tabyl(subject) %>%
adorn_totals("row") %>%
adorn_percentages("col") %>%
adorn_pct_formatting()
roster %>%
filter(hire_date > as.Date("1950-01-01")) %>%
tabyl(employee_status, full_time)
roster_raw <- read_excel("data/raw_roster.xlsx")
glimpse(roster_raw)
#| echo: FALSE
library(dtplyr)
#| echo: FALSE
library(DT)
roster_raw <- read_excel("data/raw_roster.xlsx")
roster_raw %>%
datatable()
#| echo: FALSE
roster_raw %>%
datatable( options = list(searching = FALSE))
#| echo: FALSE
roster_raw %>%
datatable( options = list(searching = FALSE,
lengthChange = FALSE
))
#| echo: FALSE
roster_raw %>%
datatable( options = list(searching = FALSE,
lengthChange = FALSE
buttons = c('copy', 'csv', 'excel')),
#| echo: FALSE
roster_raw %>%
datatable( options = list(searching = FALSE,
lengthChange = FALSE,
buttons = c('copy', 'csv', 'excel')),
extensions = 'Buttons
)
#| echo: FALSE
roster_raw %>%
datatable( options = list(searching = FALSE,
lengthChange = FALSE,
buttons = c('copy', 'csv', 'excel')),
extensions = 'Buttons'
)
vt_demographics <- tribble(
~Race, ~Year, ~Population, ~Percent,
"White (non-Hispanic)", 2000, 587155, 96.3,
"White (non-Hispanic)", 2005, 591941, 95.3,
"White (non-Hispanic)", 2010, 590817, 94.4,
"White (non-Hispanic)", 2015, 584157, 93.3,
"White (non-Hispanic)", 2021, 595151, 92.2,
"Hispanic or Latino", 2000, 5556, 0.9,
"Hispanic or Latino", 2005, 7754, 1.2,
"Hispanic or Latino", 2010, 9291, 1.5,
"Hispanic or Latino", 2015, 11214, 1.8,
"Hispanic or Latino", 2021, 14384, 2.2,
"Asian (non-Hispanic)", 2000, 5521, 0.9,
"Asian (non-Hispanic)", 2005, 6885, 1.1,
"Asian (non-Hispanic)", 2010, 8004, 1.3,
"Asian (non-Hispanic)", 2015, 10477, 1.7,
"Asian (non-Hispanic)", 2021, 12765, 2.0,
"Mixed race", 2000, 5972, 1.0,
"Mixed race", 2005, 7686, 1.2,
"Mixed race", 2010, 9543, 1.5,
"Mixed race", 2015, 10567, 1.7,
"Mixed race", 2021, 12316, 1.9,
"Black (non-Hispanic)", 2000, 3040, 0.5,
"Black (non-Hispanic)", 2005, 4590, 0.7,
"Black (non-Hispanic)", 2010, 6056, 1.0,
"Black (non-Hispanic)", 2015, 7230, 1.2,
"Black (non-Hispanic)", 2021, 8685, 1.3,
"American Indian (non-Hispanic)", 2000, 2374, 0.4,
"American Indian (non-Hispanic)", 2005, 2215, 0.4,
"American Indian (non-Hispanic)", 2010, 2030, 0.3,
"American Indian (non-Hispanic)", 2015, 1993, 0.3,
"American Indian (non-Hispanic)", 2021, 2082, 0.3
)
library(tidyverse)
vt_demographics <- tribble(
~Race, ~Year, ~Population, ~Percent,
"White (non-Hispanic)", 2000, 587155, 96.3,
"White (non-Hispanic)", 2005, 591941, 95.3,
"White (non-Hispanic)", 2010, 590817, 94.4,
"White (non-Hispanic)", 2015, 584157, 93.3,
"White (non-Hispanic)", 2021, 595151, 92.2,
"Hispanic or Latino", 2000, 5556, 0.9,
"Hispanic or Latino", 2005, 7754, 1.2,
"Hispanic or Latino", 2010, 9291, 1.5,
"Hispanic or Latino", 2015, 11214, 1.8,
"Hispanic or Latino", 2021, 14384, 2.2,
"Asian (non-Hispanic)", 2000, 5521, 0.9,
"Asian (non-Hispanic)", 2005, 6885, 1.1,
"Asian (non-Hispanic)", 2010, 8004, 1.3,
"Asian (non-Hispanic)", 2015, 10477, 1.7,
"Asian (non-Hispanic)", 2021, 12765, 2.0,
"Mixed race", 2000, 5972, 1.0,
"Mixed race", 2005, 7686, 1.2,
"Mixed race", 2010, 9543, 1.5,
"Mixed race", 2015, 10567, 1.7,
"Mixed race", 2021, 12316, 1.9,
"Black (non-Hispanic)", 2000, 3040, 0.5,
"Black (non-Hispanic)", 2005, 4590, 0.7,
"Black (non-Hispanic)", 2010, 6056, 1.0,
"Black (non-Hispanic)", 2015, 7230, 1.2,
"Black (non-Hispanic)", 2021, 8685, 1.3,
"American Indian (non-Hispanic)", 2000, 2374, 0.4,
"American Indian (non-Hispanic)", 2005, 2215, 0.4,
"American Indian (non-Hispanic)", 2010, 2030, 0.3,
"American Indian (non-Hispanic)", 2015, 1993, 0.3,
"American Indian (non-Hispanic)", 2021, 2082, 0.3
)
vt_demographics
View(vt_demographics)
URL <- read_html("https://www.imdb.com/search/title/?title_type=feature&year=2023-01-01,2023-07-31")
#LOAD PACKAGES
library(tidyverse)
library(rvest)
URL <- read_html("https://www.imdb.com/search/title/?title_type=feature&year=2023-01-01,2023-07-31")
URL <- read_html("https://www.imdb.com/search/title/?title_type=feature&release_date=2024-01-01,2024-12-31")
View(URL)
data <- URL %>%
html_elements(".title") %>%
html_text()
data
data <- URL %>%
html_elements(".cl-static-search-result a") %>%
html_text()
data
URL <- read_html("https://www.goodreads.com/genres/science")
URL <- read_html("https://www.goodreads.com/shelf/show/science")
data <- URL %>%
html_elements(".bookTitle") %>%
html_text()
data
titles <- URL %>%
html_elements(".authorName") %>%
html_text()
titles
authors <- URL %>%
html_elements(".authorName") %>%
html_text()
authors
info <- URL %>%
html_elements(".greyText") %>%
html_text()
info
lenth(titles)
length(titles)
length(authors)
length(info)
info <- URL %>%
html_elements(".smallText") %>%
html_text()
info
info <- URL %>%
html_elements(".GreyText .smallText") %>%
html_text()
info
info <- URL %>%
html_elements(".greyText .smallText") %>%
html_text()
info
info <- URL %>%
html_elements(".greyText smallText") %>%
html_text()
info
info <- URL %>%
html_elements(".smallText") %>%
html_text()
info
info <- URL %>%
html_elements(".smallText", ".greyText") %>%
html_text()
info <- URL %>%
html_elements(".greyText.smallText") %>%
html_text()
info
info <- URL %>%
html_elements(".greyText.smallText") %>%
html_text()
info
length(info)
info <- URL %>%
html_elements(".authorName") %>%
html_text()
info
info <- URL %>%
html_elements(".greyText") %>%
html_text()
info
info <- URL %>%
html_elements(".authorName__container") %>%
html_text()
info
info <- URL %>%
html_elements(".greyText") %>%
html_text()
info
info <- URL %>%
html_elements(".elementList") %>%
html_text()
info
shelved <- URL %>%
html_elements(".elementList") %>%
html_text()
shelved
shelved <- URL %>%
html_elements(".elementList") %>%
html_text()  %>%
str_subset("\\(shelved .* times as science\\)")
shelved
shelved <- URL %>%
html_elements(".elementList") %>%
html_text()  %>%
str_subset("\\(shelved .* times as science\\)") %>%
str_extract(science_shelvings, "[0-9,]+")
shelved <- URL %>%
html_elements(".elementList") %>%
html_text()  %>%
str_subset("\\(shelved .* times as science\\)") %>%
str_extract("[0-9,]+")
shelved
shelved <- URL %>%
html_elements(".elementList") %>%
html_text()  %>%
str_subset("\\(shelved .* times as science\\)") %>%
str_extract("[0-9,]+")
shelved
length(shelved)
shelved <- URL %>%
html_elements(".elementList") %>%
html_text()  %>%
str_subset("\\(shelved .* times as science\\)")
shelved
shelved <- URL %>%
html_elements(".elementList") %>%
html_text()  %>%
str_subset("\\(shelved .* times as science\\)") %>%
str_extract("[0-9,]+")
shelved
titles <- titles[-13]
authors <- title[-13]
#LOAD PACKAGES
library(tidyverse)
library(rvest)
URL <- read_html("https://www.goodreads.com/shelf/show/science")
titles <- URL %>%
html_elements(".bookTitle") %>%
html_text()
titles
authors <- URL %>%
html_elements(".authorName") %>%
html_text()
authors
info <- URL %>%
html_elements(".greyText") %>%
html_text()
info
length(titles)
length(authors)
length(info)
titles <- titles[-13]
authors <- authors[-13]
length(titles)
length(authors)
length(info)
#LOAD PACKAGES
library(tidyverse)
library(rvest)
URL <- read_html("https://www.goodreads.com/shelf/show/science")
titles <- URL %>%
html_elements(".bookTitle") %>%
html_text()
titles
authors <- URL %>%
html_elements(".authorName") %>%
html_text()
authors
info <- URL %>%
html_elements(".greyText") %>%
html_text()
info
length(titles)
length(authors)
length(info)
length(titles)
length(authors)
length(info)
authors <- authors[-13]
info <- URL %>%
html_elements(".greyText.smallText") %>%
html_text()
info
length(info)
info <- URL %>%
html_elements(".greyText.smallText") %>%
html_text()
info
info <- info[-12]
info <- URL %>%
html_elements(".greyText.smallText") %>%
html_text()
info
info <- info[-12]
info <- URL %>%
html_elements(".greyText.smallText") %>%
html_text()
info
info <- info[-12]
info
#LOAD PACKAGES
library(tidyverse)
library(rvest)
URL <- read_html("https://www.goodreads.com/shelf/show/science")
titles <- URL %>%
html_elements(".bookTitle") %>%
html_text()
titles
authors <- URL %>%
html_elements(".authorName") %>%
html_text()
authors
info <- URL %>%
html_elements(".greyText") %>%
html_text()
info
length(titles)
length(authors)
length(info)
authors <- authors[-13]
info <- URL %>%
html_elements(".greyText.smallText") %>%
html_text()
info
info <- info[-12]
info <- URL %>%
html_elements(".greyText.smallText") %>%
html_text()
info
info <- info[-12]
info
length(titles)
length(authors)
length(info)
books <- data.frame(Title = titles,
Author = authors,
Info = info
)
books
books <- books %>%
mutate(
# Remove newlines and trim spaces
Info = str_squish(Info),
# Extract each piece using regex
avg_rating = str_extract(Info, "(?<=avg rating )\\d+\\.\\d+"),
num_ratings = str_extract(Info, "\\d{1,3}(,\\d{3})*(?= ratings)"),
published = str_extract(Info, "(?<=published )\\d{4}")
)
View(books)
books <- books %>%
mutate(
# Remove newlines and trim spaces
Info = str_squish(Info),
# Extract each piece using regex
avg_rating = str_extract(Info, "(?<=avg rating )\\d+\\.\\d+"), ## These are called regular expressions. They look for patterns in the text.
num_ratings = str_extract(Info, "\\d{1,3}(,\\d{3})*(?= ratings)"),
published = str_extract(Info, "(?<=published )\\d{4}")
)
books <- books
mutate(
num_ratings = str_remove_all(num_ratings, ","),
avg_rating = as.numeric(avg_rating),
num_ratings = as.numeric(num_ratings),
published = as.integer(published)
)
books <- books %>%
mutate(
# Remove newlines and trim spaces
Info = str_squish(Info),
# Extract each piece using regex
avg_rating = str_extract(Info, "(?<=avg rating )\\d+\\.\\d+"),
num_ratings = str_extract(Info, "\\d{1,3}(,\\d{3})*(?= ratings)"),
published = str_extract(Info, "(?<=published )\\d{4}")
)
books <- books %>%
mutate(
# Remove newlines and trim spaces
Info = str_squish(Info),
# Extract each piece using regex
avg_rating = str_extract(Info, "(?<=avg rating )\\d+\\.\\d+"),
num_ratings = str_extract(Info, "\\d{1,3}(,\\d{3})*(?= ratings)"),
published = str_extract(Info, "(?<=published )\\d{4}")
) %>%
select(-Info)
books <- books
mutate(
num_ratings = str_remove_all(num_ratings, ","),
avg_rating = as.numeric(avg_rating),
num_ratings = as.numeric(num_ratings),
yr_published = as.numeric(published)
)
books <- books %>%
mutate(
num_ratings = str_remove_all(num_ratings, ","),
avg_rating = as.numeric(avg_rating),
num_ratings = as.numeric(num_ratings),
yr_published = as.numeric(published)
)
books <- books %>%
mutate(
num_ratings = str_remove_all(num_ratings, ",") %>%  as.numeric(),
avg_rating = as.numeric(avg_rating),
num_ratings = as.numeric(num_ratings),
yr_published = as.numeric(published)
)
books <- books %>%
mutate(
num_ratings = str_remove_all(num_ratings, ",") %>%  as.numeric(),
avg_rating = avg_rating %>%  as.numeric(),
num_ratings = num_ratings %>%  as.numeric(),
yr_published = published %>%  as.numeric()
)
books <- books %>%
mutate(
num_ratings = str_remove_all(num_ratings, ",") %>%  as.numeric(),
avg_rating = avg_rating %>%  as.numeric(),
num_ratings = num_ratings %>%  as.numeric(),
yr_published = yr_published %>%  as.numeric()
)
#LOAD PACKAGES
library(tidyverse)
library(rvest)
URL <- read_html("https://www.goodreads.com/shelf/show/science")
titles <- URL %>%
html_elements(".bookTitle") %>%
html_text()
titles
authors <- URL %>%
html_elements(".authorName") %>%
html_text()
authors
info <- URL %>%
html_elements(".greyText") %>%
html_text()
info
length(titles)
length(authors)
length(info)
authors <- authors[-13]
info <- URL %>%
html_elements(".greyText.smallText") %>%
html_text()
info
info <- info[-12]
info
length(titles)
length(authors)
length(info)
books <- data.frame(Title = titles,
Author = authors,
Info = info
)
books
books <- books %>%
mutate(
# Remove newlines and trim spaces
Info = str_squish(Info),
# Extract each piece using regex
avg_rating = str_extract(Info, "(?<=avg rating )\\d+\\.\\d+"),
num_ratings = str_extract(Info, "\\d{1,3}(,\\d{3})*(?= ratings)"),
yr_published = str_extract(Info, "(?<=published )\\d{4}")
) %>%
select(-Info)
books <- books %>%
mutate(
num_ratings = str_remove_all(num_ratings, ",") %>%  as.numeric(),
avg_rating = avg_rating %>%  as.numeric(),
num_ratings = num_ratings %>%  as.numeric(),
yr_published = yr_published %>%  as.numeric()
)
