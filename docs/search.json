[
  {
    "objectID": "CV/index.html",
    "href": "CV/index.html",
    "title": "Curriculum vitae",
    "section": "",
    "text": "Download current CV\n  \n\n\n  \n\n\n\n\n Back to top"
  },
  {
    "objectID": "courses/math103/index.html",
    "href": "courses/math103/index.html",
    "title": "EMW",
    "section": "",
    "text": "More Coming Soon!"
  },
  {
    "objectID": "courses/math103/index.html#math-103-functions",
    "href": "courses/math103/index.html#math-103-functions",
    "title": "EMW",
    "section": "",
    "text": "More Coming Soon!"
  },
  {
    "objectID": "courses/stat0118/118_janitor_notes_emw.html",
    "href": "courses/stat0118/118_janitor_notes_emw.html",
    "title": "Cleaning data using janitor",
    "section": "",
    "text": ":::call-out tip Data scientists, according to interviews and expert estimates, spend from 50 percent to 80 percent of their time mired in this more mundane labor of collecting and preparing unruly digital data, before it can be explored for useful nuggets.\n‚Äì ‚ÄúFor Big-Data Scientists, ‚ÄòJanitor Work‚Äô Is Key Hurdle to Insight‚Äù (New York Times, 2014) :::\n\n\n\nArtwork by @allisonhorst\n\n\nMore Coming Soon!\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "courses/stat0118/118_C_aggregating_notes_emw.html",
    "href": "courses/stat0118/118_C_aggregating_notes_emw.html",
    "title": "Aggregating with count(), summarize(), group_by(), case_when()",
    "section": "",
    "text": "#LOAD PACKAGES \nlibrary(tidyverse)"
  },
  {
    "objectID": "courses/stat0118/118_C_aggregating_notes_emw.html#multiple-groups",
    "href": "courses/stat0118/118_C_aggregating_notes_emw.html#multiple-groups",
    "title": "Aggregating with count(), summarize(), group_by(), case_when()",
    "section": "Multiple Groups",
    "text": "Multiple Groups\nSuppose we wish to have the average bill length and average bill depth broken down by sex AND species:\n\npenguins %&gt;%\n  group_by(species, sex) %&gt;%\n  summarise(average_bill_length = mean(bill_length_mm), \n            average_bill_depth = mean(bill_depth_mm))\n\n# A tibble: 6 √ó 4\n# Groups:   species [3]\n  species   sex    average_bill_length average_bill_depth\n  &lt;fct&gt;     &lt;fct&gt;                &lt;dbl&gt;              &lt;dbl&gt;\n1 Adelie    female                37.3               17.6\n2 Adelie    male                  40.4               19.1\n3 Chinstrap female                46.6               17.6\n4 Chinstrap male                  51.1               19.3\n5 Gentoo    female                45.6               14.2\n6 Gentoo    male                  49.5               15.7"
  },
  {
    "objectID": "courses/stat0118/118_Q_stringr_notes_emw.html#str_detect",
    "href": "courses/stat0118/118_Q_stringr_notes_emw.html#str_detect",
    "title": "Working with text with stringr",
    "section": "str_detect",
    "text": "str_detect\n\n\n\nartwork by @allisonhorst\n\n\ninputs: - string - pattern\noutput: - TRUE/FALSE\nlittle example:\n\nstr_detect(\"Welcome to data science, look at this cool data\", \"data\")\n\n[1] TRUE\n\n\n\nstr_detect(\"Welcome to data science, look at this cool data\", \"pineapple\")\n\n[1] FALSE\n\n\nI only want to take classes in Warner!\n\ncourses %&gt;% \n  filter(str_detect(location, \"WNS\"))\n\n# A tibble: 45 √ó 9\n   titles      distros department time  location professor description courseNum\n   &lt;chr&gt;       &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;       &lt;chr&gt;    \n 1 Gothic and‚Ä¶ AMR HI‚Ä¶ Program i‚Ä¶ 2:15‚Ä¶ \"Warner‚Ä¶ Michael ‚Ä¶ \"\\nThis co‚Ä¶ AMST0225‚Ä¶\n 2 Education ‚Ä¶ AMR SOC Program i‚Ä¶ 2:15‚Ä¶ \"Warner‚Ä¶ Melissa ‚Ä¶ \"\\nWhat ar‚Ä¶ BLST0115‚Ä¶\n 3 Economic S‚Ä¶ DED     Economics  2:15‚Ä¶ \"Warner‚Ä¶ Amanda G‚Ä¶ \"\\nAn intr‚Ä¶ ECON0111‚Ä¶\n 4 Introducto‚Ä¶ SOC     Economics  9:45‚Ä¶ \"Warner‚Ä¶ Raphaell‚Ä¶ \"\\nAn intr‚Ä¶ ECON0150‚Ä¶\n 5 Introducto‚Ä¶ SOC     Economics  11:1‚Ä¶ \"Warner‚Ä¶ Raphaell‚Ä¶ \"\\nAn intr‚Ä¶ ECON0150‚Ä¶\n 6 Introducto‚Ä¶ SOC     Economics  8:15‚Ä¶ \"Warner‚Ä¶ Will Pyle \"\\nAn intr‚Ä¶ ECON0155‚Ä¶\n 7 Introducto‚Ä¶ SOC     Economics  9:45‚Ä¶ \"Warner‚Ä¶ Will Pyle \"\\nAn intr‚Ä¶ ECON0155‚Ä¶\n 8 Microecono‚Ä¶ &lt;NA&gt;    Economics  12:4‚Ä¶ \"Warner‚Ä¶ &lt;NA&gt;      \"\\nMicroec‚Ä¶ ECON0255‚Ä¶\n 9 Microecono‚Ä¶ &lt;NA&gt;    Economics  2:15‚Ä¶ \"Warner‚Ä¶ &lt;NA&gt;      \"\\nMicroec‚Ä¶ ECON0255‚Ä¶\n10 Federal Re‚Ä¶ AMR DED Economics  1:30‚Ä¶ \"Warner‚Ä¶ Erin Wol‚Ä¶ \"\\nIn this‚Ä¶ ECON0360‚Ä¶\n# ‚Ñπ 35 more rows\n# ‚Ñπ 1 more variable: meet &lt;chr&gt;\n\n\nSuppose I don‚Äôt want any classes on Friday. Let‚Äôs use str_detect to find our options.\n\nnotFriday &lt;- courses %&gt;% \n  filter(!str_detect(meet, \"Friday\"))\n\nPerhaps I‚Äôm interested in immigration.\nThe regex function is used to write regular expressions in R. Regular expressions are helpful if you want to search for a pattern rather than a specific word or phrase.\nFor now, we will only use regex to ignore capitalization.\nIf you‚Äôre interested in using regular expressions at some point, this regex cheat sheet will be super helpful.\n\nimmigrationclasses &lt;- courses %&gt;% \n  filter(str_detect(description, regex(\"immigration\", ignore_case=TRUE)))\n\nimmigrationclasses\n\n# A tibble: 10 √ó 9\n   titles      distros department time  location professor description courseNum\n   &lt;chr&gt;       &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;       &lt;chr&gt;    \n 1 Immigrant ‚Ä¶ AMR HIS Program i‚Ä¶ 11:1‚Ä¶ \"Axinn ‚Ä¶ Rachael ‚Ä¶ \"\\nIn this‚Ä¶ AMST0175‚Ä¶\n 2 Introducti‚Ä¶ EUR LN‚Ä¶ French     2:15‚Ä¶ \"Le Cha‚Ä¶ William ‚Ä¶ \"\\nIn this‚Ä¶ FREN0230‚Ä¶\n 3 Introducti‚Ä¶ CW EUR‚Ä¶ French     2:15‚Ä¶ \"Le Cha‚Ä¶ William ‚Ä¶ \"\\nIn this‚Ä¶ FREN0230‚Ä¶\n 4 The United‚Ä¶ AMR HIS History    9:45‚Ä¶ \"Axinn ‚Ä¶ Joyce Mao \"\\nThis co‚Ä¶ HIST0206‚Ä¶\n 5 Introducti‚Ä¶ CMP     Internati‚Ä¶ 12:4‚Ä¶ \"Twilig‚Ä¶ Amit Pra‚Ä¶ \"\\nThis is‚Ä¶ IGST0101‚Ä¶\n 6 An Introdu‚Ä¶ EUR LN‚Ä¶ Italian    9:45‚Ä¶ \"Wright‚Ä¶ Thomas V‚Ä¶ \"\\nIntende‚Ä¶ ITAL0251‚Ä¶\n 7 An Introdu‚Ä¶ EUR LN‚Ä¶ Italian    11:1‚Ä¶ \"75 Sha‚Ä¶ Sandra C‚Ä¶ \"\\nIntende‚Ä¶ ITAL0251‚Ä¶\n 8 Globalizat‚Ä¶ SOC     Political‚Ä¶ 2:15‚Ä¶ \"Librar‚Ä¶ Orion Le‚Ä¶ \"\\nHow doe‚Ä¶ PSCI0314‚Ä¶\n 9 City Polit‚Ä¶ &lt;NA&gt;    Political‚Ä¶ 11:1‚Ä¶ \"LaForc‚Ä¶ Bert Joh‚Ä¶ \"\\nCities ‚Ä¶ PSCI0465‚Ä¶\n10 Christiani‚Ä¶ AMR HI‚Ä¶ Religion   7:30‚Ä¶ \"Librar‚Ä¶ James Ca‚Ä¶ \"\\nReligio‚Ä¶ RELI0398‚Ä¶\n# ‚Ñπ 1 more variable: meet &lt;chr&gt;"
  },
  {
    "objectID": "courses/stat0118/118_Q_stringr_notes_emw.html#str_extract-and-str_remove",
    "href": "courses/stat0118/118_Q_stringr_notes_emw.html#str_extract-and-str_remove",
    "title": "Working with text with stringr",
    "section": "str_extract and str_remove",
    "text": "str_extract and str_remove\nstr_extract inputs: - string - pattern str_extract output: - the extracted pattern, if it appears in the the string\nstr_remove inputs: - string - pattern str_extract output: - the string without the pattern, if it appears in the string\nlittle example:\n\nstr_extract(\"Welcome to data science, look at this cool data\", \"data\")\n\n[1] \"data\"\n\nstr_extract_all(\"Welcome to data science, look at this cool data\", \"data\")\n\n[[1]]\n[1] \"data\" \"data\"\n\nstr_remove(\"Welcome to data science, look at this cool data\", \"data\")\n\n[1] \"Welcome to  science, look at this cool data\"\n\nstr_remove_all(\"Welcome to data science, look at this cool data\", \"data\")\n\n[1] \"Welcome to  science, look at this cool \"\n\n\nCW is part of the distribution requirement column. I want CW to be its own column.\n\ncourses %&gt;% \n  mutate(CW = str_extract(distros, \"CW\")) %&gt;% \n  mutate(distros = str_remove(distros, \"CW\"))\n\n# A tibble: 586 √ó 10\n   titles      distros department time  location professor description courseNum\n   &lt;chr&gt;       &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;       &lt;chr&gt;    \n 1 Introducti‚Ä¶ AMR CMP Program i‚Ä¶ 12:4‚Ä¶ \"Axinn ‚Ä¶ Roberto ‚Ä¶ \"\\nIn this‚Ä¶ AMST0101‚Ä¶\n 2 Immigrant ‚Ä¶ AMR HIS Program i‚Ä¶ 11:1‚Ä¶ \"Axinn ‚Ä¶ Rachael ‚Ä¶ \"\\nIn this‚Ä¶ AMST0175‚Ä¶\n 3 American L‚Ä¶ AMR LIT Program i‚Ä¶ 11:1‚Ä¶ \"Axinn ‚Ä¶ Ellery F‚Ä¶ \"\\nA study‚Ä¶ AMST0209‚Ä¶\n 4 Introducti‚Ä¶ AMR HI‚Ä¶ Program i‚Ä¶ 1:30‚Ä¶ \"Twilig‚Ä¶ Roberto ‚Ä¶ \"\\nIn this‚Ä¶ AMST0213‚Ä¶\n 5 Gothic and‚Ä¶ AMR HI‚Ä¶ Program i‚Ä¶ 2:15‚Ä¶ \"Warner‚Ä¶ Michael ‚Ä¶ \"\\nThis co‚Ä¶ AMST0225‚Ä¶\n 6 American C‚Ä¶ AMR HIS Program i‚Ä¶ 9:45‚Ä¶ \"Axinn ‚Ä¶ Holly Al‚Ä¶ \"\\nFor man‚Ä¶ AMST0234‚Ä¶\n 7 Constructi‚Ä¶ AMR ART Program i‚Ä¶ 1:30‚Ä¶ \"Ross C‚Ä¶ Deb Evans \"\\n‚ÄúDemocr‚Ä¶ AMST0251‚Ä¶\n 8 African Am‚Ä¶ AMR LIT Program i‚Ä¶ 9:45‚Ä¶ \"Axinn ‚Ä¶ William ‚Ä¶ \"\\nThis co‚Ä¶ AMST0252‚Ä¶\n 9 American D‚Ä¶ AMR HI‚Ä¶ Program i‚Ä¶ 11:1‚Ä¶ \"Axinn ‚Ä¶ Susan Bu‚Ä¶ \"\\nIn this‚Ä¶ AMST0260‚Ä¶\n10 Chicagoland AMR HIS Program i‚Ä¶ 11:1‚Ä¶ \"Giffor‚Ä¶ Jim Ralp‚Ä¶ \"\\nIn this‚Ä¶ AMST0264‚Ä¶\n# ‚Ñπ 576 more rows\n# ‚Ñπ 2 more variables: meet &lt;chr&gt;, CW &lt;chr&gt;"
  },
  {
    "objectID": "courses/stat0118/118_Q_stringr_notes_emw.html#str_sub",
    "href": "courses/stat0118/118_Q_stringr_notes_emw.html#str_sub",
    "title": "Working with text with stringr",
    "section": "str_sub",
    "text": "str_sub\nstr_sub inputs: - string\n- starting character - ending character str_sub output: - string with only the characters between the start and the end\nlittle example:\n\nstr_sub(\"Welcome to data science, look at this cool data\", start=12, end=23) \n\n[1] \"data science\"\n\n\n\nBounds are inclusive!\n\nMaybe I only want 200 level math classes.\n\nFirst we filter for just math classes.\nThen we can create a new column called level that contains only the sixth character from the courses column.\n\nWe call this a substring, hence the function str_sub.\n\nMathClasses &lt;- courses %&gt;% \n  filter(department == \"Mathematics\") %&gt;% \n  mutate(level=str_sub(courseNum, start=6, end=6)) \n\nMath2Classes &lt;- MathClasses %&gt;% \n  filter(level== \"2\")"
  },
  {
    "objectID": "courses/stat0118/118_Q_stringr_notes_emw.html#str_count",
    "href": "courses/stat0118/118_Q_stringr_notes_emw.html#str_count",
    "title": "Working with text with stringr",
    "section": "str_count",
    "text": "str_count\nstr_count inputs: - string\n- pattern str_count output: - a count of the number of times the pattern appears in the string\nlittle example:\n\nstr_count(\"Welcome to data science, look at this cool data\", \"data\")\n\n[1] 2\n\n\nMaybe I only want my classes to meet twice a week.\n\ncourses &lt;- courses %&gt;% \n  mutate(dayCount = str_count(meet, \"day\"))\n\n#what's the maximum number of days a week a class meets?\nmax(courses$dayCount)\n\n[1] 5\n\n#what's the mean number of days?\nmean(courses$dayCount)\n\n[1] 2.187713\n\n\nLet‚Äôs visualize this data.\n\ncourses %&gt;% \n  ggplot() + \n  geom_bar(aes(x=dayCount), fill=\"blue\") + \n  xlab(\"Number of Days Class Meets\") + \n  ylab(\"Number of Classes\") + \n  labs(title=\"How many Days a Week do Classes at Middlebury Meet?\")+\n  theme_classic()"
  },
  {
    "objectID": "courses/stat0118/118_J_pivoting_notes_emw.html",
    "href": "courses/stat0118/118_J_pivoting_notes_emw.html",
    "title": "reshaping data with tidyr",
    "section": "",
    "text": "The goal of tidyr is to help you create tidy data.\n\n\n\nIllustrations from the Openscapes blog Tidy Data for reproducibility, efficiency, and collaboration by Julia Lowndes and Allison Horst\n\n\n\n\n\nhttps://r4ds.hadley.nz/data-tidy\n\n\n\nReshaping with Pivoting ‚Äì Why?\nData frames are often described as wide or long.\nWide when a row has more than one observation, and the units of observation are on one row each\nLong when a row has only one observation, but the units of observation are repeated down the column\n\n\n\nCredit: datasciencebook.ca\n\n\n\n\ncanlang dataset\n\n#LOAD PACKAGES\nlibrary(tidyverse)\n\n#LOAD DATA\nlang_wide &lt;- read.csv(\"https://raw.githubusercontent.com/UBC-DSCI/introduction-to-datascience/master/data/region_lang_top5_cities_wide.csv\")\n\n\n\nPivot Longer\n \n\nlang_mother_tidy &lt;- pivot_longer(lang_wide,\n  cols = Toronto:Edmonton,\n  names_to = \"region\",\n  values_to = \"mother_tongue\"\n)\n\nlang_mother_tidy\n\n# A tibble: 1,070 √ó 4\n   category                                language         region mother_tongue\n   &lt;chr&gt;                                   &lt;chr&gt;            &lt;chr&gt;          &lt;int&gt;\n 1 Aboriginal languages                    Aboriginal lang‚Ä¶ Toron‚Ä¶            80\n 2 Aboriginal languages                    Aboriginal lang‚Ä¶ Montr‚Ä¶            30\n 3 Aboriginal languages                    Aboriginal lang‚Ä¶ Vanco‚Ä¶            70\n 4 Aboriginal languages                    Aboriginal lang‚Ä¶ Calga‚Ä¶            20\n 5 Aboriginal languages                    Aboriginal lang‚Ä¶ Edmon‚Ä¶            25\n 6 Non-Official & Non-Aboriginal languages Afrikaans        Toron‚Ä¶           985\n 7 Non-Official & Non-Aboriginal languages Afrikaans        Montr‚Ä¶            90\n 8 Non-Official & Non-Aboriginal languages Afrikaans        Vanco‚Ä¶          1435\n 9 Non-Official & Non-Aboriginal languages Afrikaans        Calga‚Ä¶           960\n10 Non-Official & Non-Aboriginal languages Afrikaans        Edmon‚Ä¶           575\n# ‚Ñπ 1,060 more rows\n\n\nThe data above is now tidy because all three criteria for tidy data have now been met:\n\nAll the variables (category, language, region and mother_tongue) are now their own columns in the data frame.\nEach observation, (i.e., each language in a region) is in a single row.\nEach value is a single cell, i.e., its row, column position in the data frame is not shared with another value.\n\n\n\nPivot Wider\n\nlang_long &lt;- read.csv(\"https://raw.githubusercontent.com/UBC-DSCI/introduction-to-datascience/master/data/region_lang_top5_cities_long.csv\")\n\n \n\nlang_home_tidy &lt;- pivot_wider(lang_long,\n  names_from = type,\n  values_from = count\n)\nlang_home_tidy\n\n# A tibble: 1,070 √ó 5\n   region    category                         language most_at_home most_at_work\n   &lt;chr&gt;     &lt;chr&gt;                            &lt;chr&gt;           &lt;int&gt;        &lt;int&gt;\n 1 Montr√©al  Aboriginal languages             Aborigi‚Ä¶           15            0\n 2 Toronto   Aboriginal languages             Aborigi‚Ä¶           50            0\n 3 Calgary   Aboriginal languages             Aborigi‚Ä¶            5            0\n 4 Edmonton  Aboriginal languages             Aborigi‚Ä¶           10            0\n 5 Vancouver Aboriginal languages             Aborigi‚Ä¶           15            0\n 6 Montr√©al  Non-Official & Non-Aboriginal l‚Ä¶ Afrikaa‚Ä¶           10            0\n 7 Toronto   Non-Official & Non-Aboriginal l‚Ä¶ Afrikaa‚Ä¶          265            0\n 8 Calgary   Non-Official & Non-Aboriginal l‚Ä¶ Afrikaa‚Ä¶          505           15\n 9 Edmonton  Non-Official & Non-Aboriginal l‚Ä¶ Afrikaa‚Ä¶          300            0\n10 Vancouver Non-Official & Non-Aboriginal l‚Ä¶ Afrikaa‚Ä¶          520           10\n# ‚Ñπ 1,060 more rows\n\n\n\n\n\nGapminder\n\nlibrary(gapminder)\ndata(\"gapminder\")\n\nLet‚Äôs say we‚Äôd like to look at LifeExp over time for all the countries in Asia in our dataset.\n\n# Create a dataset called asia with the data we need\nasia &lt;- gapminder %&gt;% \n  filter(continent == \"Asia\") %&gt;% \n  select(country, year, lifeExp)\n\nWe can create a wide version of our table, where each row is a country and each column a year, with values of lifeExp in each cell of the table.\n\nlifeExp_wide &lt;- asia %&gt;% \n1  pivot_wider(names_from = \"year\",\n2              names_prefix = \"yr\",\n              values_from = \"lifeExp\")\nlifeExp_wide\n\n\n1\n\nuse pivot_wider to go from long to wide format\n\n2\n\nAdds the pre-fix ‚Äúyr‚Äù to all the column names ‚Äì it‚Äôs a good idea to avoid column names that start with a number.\n\n\n\n\n# A tibble: 33 √ó 13\n   country yr1952 yr1957 yr1962 yr1967 yr1972 yr1977 yr1982 yr1987 yr1992 yr1997\n   &lt;fct&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1 Afghan‚Ä¶   28.8   30.3   32.0   34.0   36.1   38.4   39.9   40.8   41.7   41.8\n 2 Bahrain   50.9   53.8   56.9   59.9   63.3   65.6   69.1   70.8   72.6   73.9\n 3 Bangla‚Ä¶   37.5   39.3   41.2   43.5   45.3   46.9   50.0   52.8   56.0   59.4\n 4 Cambod‚Ä¶   39.4   41.4   43.4   45.4   40.3   31.2   51.0   53.9   55.8   56.5\n 5 China     44     50.5   44.5   58.4   63.1   64.0   65.5   67.3   68.7   70.4\n 6 Hong K‚Ä¶   61.0   64.8   67.6   70     72     73.6   75.4   76.2   77.6   80  \n 7 India     37.4   40.2   43.6   47.2   50.7   54.2   56.6   58.6   60.2   61.8\n 8 Indone‚Ä¶   37.5   39.9   42.5   46.0   49.2   52.7   56.2   60.1   62.7   66.0\n 9 Iran      44.9   47.2   49.3   52.5   55.2   57.7   59.6   63.0   65.7   68.0\n10 Iraq      45.3   48.4   51.5   54.5   57.0   60.4   62.0   65.0   59.5   58.8\n# ‚Ñπ 23 more rows\n# ‚Ñπ 2 more variables: yr2002 &lt;dbl&gt;, yr2007 &lt;dbl&gt;\n\n\n\n\n\n\n\n\nExternal Resources\n\n\n\n\nR for Data Science, Data Tidying\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "courses/stat0118/118_B_wrangling_notes_emw.html",
    "href": "courses/stat0118/118_B_wrangling_notes_emw.html",
    "title": "filter, select, arrange, slice, mutate",
    "section": "",
    "text": "Downloads for this page:\n\n\n\n\nüìñ Complete Notes .qmd\nüìù Blank Notes Template .qmd\nüìö Homework .qmd\n\n\n\n\nInstalling and Using Packages\nSometimes everything we need (data, functions, etc) are not available in base R. In R, expert users will package up useful things like data and functions into packages that be download and used.\nFirst, you need to download the package from the right hand menu ‚Äì&gt; You only need to do this once.\nIn each new .qmd document, you need to call any packages you want to use but adding the code library(packagename) inside an R chunk.\nFor example, in this class we will use the tidyverse package a lot.\n\n1library(tidyverse)\n\n\n1\n\nLoads the tidyverse package\n\n\n\n\nThere are actually many commonly used packages wrapped up inside one tidyverse package.\n\n\n\nCredit: https://uopsych-r-bootcamp-2020.netlify.app/\n\n\nToday we are specifically going to be talking about the package dplyr which is useful to manipulating data sets.\n\n\ncan_lang dataset\n\nIn this class, we are going to be working with a dataset relating to the languages spoken at home by Canadian residents. Many Indigenous peoples exist in Canada with their own languages and cultures. Sadly, colonization has led to the loss of many of these languages. This data is a subset of data collected during the 2016 census.\n\n\nImporting Data\nWhat is a .csv file?\nHow do we import it into R?\nUse read.csv()! Note that your data file (.csv) needs to be saved in the same folder as your notes template document (.qmd).\n\n1can_lang &lt;- read.csv(\"data/can_lang.csv\")\n\n\n1\n\nTakes the can_lang.csv file (located in the same folder as your .qmd file), reads it into R, and saves it as the dataset can_lang\n\n\n\n\nAlternatively, you can download it directly from the internet. Github user ttimbers hosts this file to share with the public at the link: https://raw.githubusercontent.com/ttimbers/canlang/master/inst/extdata/can_lang.csv\n\n1can_lang &lt;- read.csv(\"https://raw.githubusercontent.com/ttimbers/canlang/master/inst/extdata/can_lang.csv\")\n\n\n1\n\nTakes the dataset located at the given url, reads it into R, and saves it as the dataset can_lang\n\n\n\n\nLet‚Äôs take a look at this data for a minute to see what information has been recorded. In the environment in the top left, if you click on the word can_lang (not the blue play button, the word itself) it will open the object so you can see what is saved inside. Alternatively you can use the head() function to display just the first few rows of the dataset.\n\nhead(can_lang)\n\n                                 category                       language\n1                    Aboriginal languages   Aboriginal languages, n.o.s.\n2 Non-Official & Non-Aboriginal languages                      Afrikaans\n3 Non-Official & Non-Aboriginal languages Afro-Asiatic languages, n.i.e.\n4 Non-Official & Non-Aboriginal languages                     Akan (Twi)\n5 Non-Official & Non-Aboriginal languages                       Albanian\n6                    Aboriginal languages   Algonquian languages, n.i.e.\n  mother_tongue most_at_home most_at_work lang_known\n1           590          235           30        665\n2         10260         4785           85      23415\n3          1150          445           10       2775\n4         13460         5985           25      22150\n5         26895        13135          345      31930\n6            45           10            0        120\n\n\n\n\nfilter\nWe can use the filter function to extract rows from the data that have a particular characteristic.\n\n\n\nArtwork by @allisonhorst\n\n\nFor example, we may be interested in only looking at only the languages in this dataset that are Aboriginal languages.\nStart with the can_lang dataset, the pipe ‚Äú%&gt;%‚Äù means apply the action on the following line to the previous line.\n\n1can_lang  %&gt;%\n2  filter(category == \"Aboriginal languages\")\n\n\n1\n\nbegin with the can_lang dataset\n\n2\n\nonly include the rows were the category variable is ‚ÄúAboriginal languages‚Äù\n\n\n\n\n               category                     language mother_tongue most_at_home\n1  Aboriginal languages Aboriginal languages, n.o.s.           590          235\n2  Aboriginal languages Algonquian languages, n.i.e.            45           10\n3  Aboriginal languages                    Algonquin          1260          370\n4  Aboriginal languages Athabaskan languages, n.i.e.            50           10\n5  Aboriginal languages                    Atikamekw          6150         5465\n6  Aboriginal languages         Babine (Wetsuwet'en)           110           20\n7  Aboriginal languages                       Beaver           190           50\n8  Aboriginal languages                    Blackfoot          2815         1110\n9  Aboriginal languages                      Carrier          1025          250\n10 Aboriginal languages                       Cayuga            45           10\n11 Aboriginal languages                    Chilcotin           655          255\n12 Aboriginal languages                        Comox            85            0\n13 Aboriginal languages                 Cree, n.o.s.         64050        37950\n14 Aboriginal languages                       Dakota          1210          255\n15 Aboriginal languages                         Dene         10700         7710\n16 Aboriginal languages              Dogrib (Tlicho)          1650         1020\n17 Aboriginal languages            Gitxsan (Gitksan)           880          315\n18 Aboriginal languages                     Gwich'in           255           50\n19 Aboriginal languages                        Haida            80           10\n20 Aboriginal languages                       Haisla            90           20\n21 Aboriginal languages                   Halkomelem           480           50\n22 Aboriginal languages                     Heiltsuk           100            5\n23 Aboriginal languages   Inuinnaqtun (Inuvialuktun)          1020          165\n24 Aboriginal languages      Inuit languages, n.i.e.           310           90\n25 Aboriginal languages                    Inuktitut         35210        29230\n26 Aboriginal languages  Iroquoian languages, n.i.e.            35            5\n27 Aboriginal languages               Kaska (Nahani)           180           20\n28 Aboriginal languages                      Kutenai           110           10\n29 Aboriginal languages         Kwakiutl (Kwak'wala)           325           25\n30 Aboriginal languages                     Lillooet           315           25\n31 Aboriginal languages                     Malecite           300           55\n32 Aboriginal languages                      Mi'kmaq          6690         3565\n33 Aboriginal languages                       Michif           465           80\n34 Aboriginal languages                       Mohawk           985          255\n35 Aboriginal languages            Montagnais (Innu)         10235         8585\n36 Aboriginal languages                   Moose Cree           105           10\n37 Aboriginal languages                      Naskapi          1205         1195\n38 Aboriginal languages                      Nisga'a           400           75\n39 Aboriginal languages          North Slavey (Hare)           765          340\n40 Aboriginal languages           Northern East Cree           315          110\n41 Aboriginal languages            Northern Tutchone           220           30\n42 Aboriginal languages      Nuu-chah-nulth (Nootka)           280           30\n43 Aboriginal languages                     Oji-Cree         12855         7905\n44 Aboriginal languages                      Ojibway         17885         6175\n45 Aboriginal languages                     Okanagan           275           80\n46 Aboriginal languages                       Oneida            60           15\n47 Aboriginal languages               Ottawa (Odawa)           150           75\n48 Aboriginal languages                  Plains Cree          3065         1345\n49 Aboriginal languages     Salish languages, n.i.e.           260           25\n50 Aboriginal languages               Sarsi (Sarcee)            80           10\n51 Aboriginal languages                       Sekani            85           15\n52 Aboriginal languages      Shuswap (Secwepemctsin)           445           50\n53 Aboriginal languages     Siouan languages, n.i.e.            55           20\n54 Aboriginal languages               Slavey, n.o.s.           280          105\n55 Aboriginal languages                 South Slavey           945          370\n56 Aboriginal languages           Southern East Cree            45           15\n57 Aboriginal languages            Southern Tutchone            70            5\n58 Aboriginal languages                     Squamish            40            5\n59 Aboriginal languages                       Stoney          3025         1950\n60 Aboriginal languages                      Straits            80           25\n61 Aboriginal languages                  Swampy Cree          1440          330\n62 Aboriginal languages                      Tahltan            95            5\n63 Aboriginal languages       Thompson (Ntlakapamux)           335           20\n64 Aboriginal languages                      Tlingit            95            0\n65 Aboriginal languages                    Tsimshian           200           30\n66 Aboriginal languages   Wakashan languages, n.i.e.            10            0\n67 Aboriginal languages                   Woods Cree          1840          800\n   most_at_work lang_known\n1            30        665\n2             0        120\n3            40       2480\n4             0         85\n5          1100       6645\n6            10        210\n7             0        340\n8            85       5645\n9            15       2100\n10           10        125\n11           15       1150\n12            0        185\n13         7800      86115\n14           20       1760\n15          770      13060\n16          165       2375\n17           10       1305\n18           10        360\n19            0        465\n20            0        175\n21           20       1060\n22           10        125\n23           30       1975\n24           15        470\n25         8795      40620\n26            0        115\n27           10        365\n28            0        170\n29           15        605\n30           15        790\n31           10        760\n32          915       9025\n33           10       1210\n34           30       2415\n35         2055      11445\n36            0        195\n37          370       1465\n38           10       1055\n39           95       1005\n40           35        550\n41            0        280\n42           10        560\n43         1080      15605\n44          765      28580\n45           20        820\n46            0        185\n47            0        205\n48           95       5905\n49            0        560\n50            0        145\n51            0        185\n52           35       1305\n53            0        140\n54           10        675\n55           35       1365\n56            0         40\n57            0        145\n58           10        285\n59          240       3675\n60           15        365\n61           10       2350\n62            0        265\n63            0        450\n64           10        260\n65           10        410\n66            0         25\n67           75       2665\n\n\nSome notes:\n\nthe aboriginal languages is text/categorical and so quotation marks are needed.\nR doesn‚Äôt care about whether they are double quotation marks (‚Äú) or single (‚Äô). They work the same.\nIf we don‚Äôt assign it to an object, then it just prints out for us to see!\n\nOftentimes, we want to take our subset and give it a new name. This takes our subset and assigns it to a new dataset called aboriginal_lang.\n\n1aboriginal_lang &lt;- can_lang  %&gt;%\n  filter(category == \"Aboriginal languages\")  \n\n\n1\n\nThe code aboriginal_lang &lt;- takes the given data (the Aboriginal languages in the can_lang dataset) and saves it as a new object called aboriginal_lang.\n\n\n\n\nNotes:\n\nNotice if you assign it to an object that it doesn‚Äôt print out the contents.\nYou‚Äôll see the new object in your environment on the top right ‚Äî&gt;\n\nIt can also be used with numeric criteria.\nSuppose we want a list of all the languages in Canada that are spoken by less than 100 people as their mother tongue.\n\n1rare_lang &lt;- can_lang  %&gt;%\n2  filter(mother_tongue &lt; 100)\n3\n\n\n1\n\nbegin with the can_lang dataset\n\n2\n\nonly include the rows were the number of people who speak the language as their mother tongue is more than 100 people\n\n3\n\ndata saved to the object rare_lang\n\n\n\n\nThe logical operators are given below:\n\n\n\nOperator\nDescription\n\n\n\n\n&lt;\nLess than\n\n\n&gt;\nGreater than\n\n\n&lt;=\nLess than or equal to\n\n\n&gt;=\nGreater than or equal to\n\n\n==\nEqual to\n\n\n!=\nNot equal to\n\n\n!x\nNot x\n\n\nx | y\nx OR y\n\n\nx & y\nx AND y\n\n\n\n\n\nselect\nselect is used to extract only certain columns. For example, perhaps we only want to print out a list names of the aboriginal languages (language column).\n\n1aboriginal_lang %&gt;%\n2  select(language)\n\n\n1\n\nBegin with the aboriginal_lang dataset\n\n2\n\nonly include the language column\n\n\n\n\n                       language\n1  Aboriginal languages, n.o.s.\n2  Algonquian languages, n.i.e.\n3                     Algonquin\n4  Athabaskan languages, n.i.e.\n5                     Atikamekw\n6          Babine (Wetsuwet'en)\n7                        Beaver\n8                     Blackfoot\n9                       Carrier\n10                       Cayuga\n11                    Chilcotin\n12                        Comox\n13                 Cree, n.o.s.\n14                       Dakota\n15                         Dene\n16              Dogrib (Tlicho)\n17            Gitxsan (Gitksan)\n18                     Gwich'in\n19                        Haida\n20                       Haisla\n21                   Halkomelem\n22                     Heiltsuk\n23   Inuinnaqtun (Inuvialuktun)\n24      Inuit languages, n.i.e.\n25                    Inuktitut\n26  Iroquoian languages, n.i.e.\n27               Kaska (Nahani)\n28                      Kutenai\n29         Kwakiutl (Kwak'wala)\n30                     Lillooet\n31                     Malecite\n32                      Mi'kmaq\n33                       Michif\n34                       Mohawk\n35            Montagnais (Innu)\n36                   Moose Cree\n37                      Naskapi\n38                      Nisga'a\n39          North Slavey (Hare)\n40           Northern East Cree\n41            Northern Tutchone\n42      Nuu-chah-nulth (Nootka)\n43                     Oji-Cree\n44                      Ojibway\n45                     Okanagan\n46                       Oneida\n47               Ottawa (Odawa)\n48                  Plains Cree\n49     Salish languages, n.i.e.\n50               Sarsi (Sarcee)\n51                       Sekani\n52      Shuswap (Secwepemctsin)\n53     Siouan languages, n.i.e.\n54               Slavey, n.o.s.\n55                 South Slavey\n56           Southern East Cree\n57            Southern Tutchone\n58                     Squamish\n59                       Stoney\n60                      Straits\n61                  Swampy Cree\n62                      Tahltan\n63       Thompson (Ntlakapamux)\n64                      Tlingit\n65                    Tsimshian\n66   Wakashan languages, n.i.e.\n67                   Woods Cree\n\n\nWe can combine criteria together as well in one command with multiple pipes:\n\ncan_lang %&gt;% \n  filter(category == \"Aboriginal languages\") %&gt;% \n  select(language)\n\n                       language\n1  Aboriginal languages, n.o.s.\n2  Algonquian languages, n.i.e.\n3                     Algonquin\n4  Athabaskan languages, n.i.e.\n5                     Atikamekw\n6          Babine (Wetsuwet'en)\n7                        Beaver\n8                     Blackfoot\n9                       Carrier\n10                       Cayuga\n11                    Chilcotin\n12                        Comox\n13                 Cree, n.o.s.\n14                       Dakota\n15                         Dene\n16              Dogrib (Tlicho)\n17            Gitxsan (Gitksan)\n18                     Gwich'in\n19                        Haida\n20                       Haisla\n21                   Halkomelem\n22                     Heiltsuk\n23   Inuinnaqtun (Inuvialuktun)\n24      Inuit languages, n.i.e.\n25                    Inuktitut\n26  Iroquoian languages, n.i.e.\n27               Kaska (Nahani)\n28                      Kutenai\n29         Kwakiutl (Kwak'wala)\n30                     Lillooet\n31                     Malecite\n32                      Mi'kmaq\n33                       Michif\n34                       Mohawk\n35            Montagnais (Innu)\n36                   Moose Cree\n37                      Naskapi\n38                      Nisga'a\n39          North Slavey (Hare)\n40           Northern East Cree\n41            Northern Tutchone\n42      Nuu-chah-nulth (Nootka)\n43                     Oji-Cree\n44                      Ojibway\n45                     Okanagan\n46                       Oneida\n47               Ottawa (Odawa)\n48                  Plains Cree\n49     Salish languages, n.i.e.\n50               Sarsi (Sarcee)\n51                       Sekani\n52      Shuswap (Secwepemctsin)\n53     Siouan languages, n.i.e.\n54               Slavey, n.o.s.\n55                 South Slavey\n56           Southern East Cree\n57            Southern Tutchone\n58                     Squamish\n59                       Stoney\n60                      Straits\n61                  Swampy Cree\n62                      Tahltan\n63       Thompson (Ntlakapamux)\n64                      Tlingit\n65                    Tsimshian\n66   Wakashan languages, n.i.e.\n67                   Woods Cree\n\n\n\n\narrange\nThe arrange function allows us to order the rows of the data frame by the values of a particular column.\nFor example, arrange all the aboriginal languages in canada by from most to least spoken as mother tongue.\n\naboriginal_lang %&gt;% \n1  arrange(desc(mother_tongue))\n\n\n1\n\narranges the languages from the language with the most to the least people who speak the language as their mother tongue\n\n\n\n\n               category                     language mother_tongue most_at_home\n1  Aboriginal languages                 Cree, n.o.s.         64050        37950\n2  Aboriginal languages                    Inuktitut         35210        29230\n3  Aboriginal languages                      Ojibway         17885         6175\n4  Aboriginal languages                     Oji-Cree         12855         7905\n5  Aboriginal languages                         Dene         10700         7710\n6  Aboriginal languages            Montagnais (Innu)         10235         8585\n7  Aboriginal languages                      Mi'kmaq          6690         3565\n8  Aboriginal languages                    Atikamekw          6150         5465\n9  Aboriginal languages                  Plains Cree          3065         1345\n10 Aboriginal languages                       Stoney          3025         1950\n11 Aboriginal languages                    Blackfoot          2815         1110\n12 Aboriginal languages                   Woods Cree          1840          800\n13 Aboriginal languages              Dogrib (Tlicho)          1650         1020\n14 Aboriginal languages                  Swampy Cree          1440          330\n15 Aboriginal languages                    Algonquin          1260          370\n16 Aboriginal languages                       Dakota          1210          255\n17 Aboriginal languages                      Naskapi          1205         1195\n18 Aboriginal languages                      Carrier          1025          250\n19 Aboriginal languages   Inuinnaqtun (Inuvialuktun)          1020          165\n20 Aboriginal languages                       Mohawk           985          255\n21 Aboriginal languages                 South Slavey           945          370\n22 Aboriginal languages            Gitxsan (Gitksan)           880          315\n23 Aboriginal languages          North Slavey (Hare)           765          340\n24 Aboriginal languages                    Chilcotin           655          255\n25 Aboriginal languages Aboriginal languages, n.o.s.           590          235\n26 Aboriginal languages                   Halkomelem           480           50\n27 Aboriginal languages                       Michif           465           80\n28 Aboriginal languages      Shuswap (Secwepemctsin)           445           50\n29 Aboriginal languages                      Nisga'a           400           75\n30 Aboriginal languages       Thompson (Ntlakapamux)           335           20\n31 Aboriginal languages         Kwakiutl (Kwak'wala)           325           25\n32 Aboriginal languages                     Lillooet           315           25\n33 Aboriginal languages           Northern East Cree           315          110\n34 Aboriginal languages      Inuit languages, n.i.e.           310           90\n35 Aboriginal languages                     Malecite           300           55\n36 Aboriginal languages      Nuu-chah-nulth (Nootka)           280           30\n37 Aboriginal languages               Slavey, n.o.s.           280          105\n38 Aboriginal languages                     Okanagan           275           80\n39 Aboriginal languages     Salish languages, n.i.e.           260           25\n40 Aboriginal languages                     Gwich'in           255           50\n41 Aboriginal languages            Northern Tutchone           220           30\n42 Aboriginal languages                    Tsimshian           200           30\n43 Aboriginal languages                       Beaver           190           50\n44 Aboriginal languages               Kaska (Nahani)           180           20\n45 Aboriginal languages               Ottawa (Odawa)           150           75\n46 Aboriginal languages         Babine (Wetsuwet'en)           110           20\n47 Aboriginal languages                      Kutenai           110           10\n48 Aboriginal languages                   Moose Cree           105           10\n49 Aboriginal languages                     Heiltsuk           100            5\n50 Aboriginal languages                      Tahltan            95            5\n51 Aboriginal languages                      Tlingit            95            0\n52 Aboriginal languages                       Haisla            90           20\n53 Aboriginal languages                        Comox            85            0\n54 Aboriginal languages                       Sekani            85           15\n55 Aboriginal languages                        Haida            80           10\n56 Aboriginal languages               Sarsi (Sarcee)            80           10\n57 Aboriginal languages                      Straits            80           25\n58 Aboriginal languages            Southern Tutchone            70            5\n59 Aboriginal languages                       Oneida            60           15\n60 Aboriginal languages     Siouan languages, n.i.e.            55           20\n61 Aboriginal languages Athabaskan languages, n.i.e.            50           10\n62 Aboriginal languages Algonquian languages, n.i.e.            45           10\n63 Aboriginal languages                       Cayuga            45           10\n64 Aboriginal languages           Southern East Cree            45           15\n65 Aboriginal languages                     Squamish            40            5\n66 Aboriginal languages  Iroquoian languages, n.i.e.            35            5\n67 Aboriginal languages   Wakashan languages, n.i.e.            10            0\n   most_at_work lang_known\n1          7800      86115\n2          8795      40620\n3           765      28580\n4          1080      15605\n5           770      13060\n6          2055      11445\n7           915       9025\n8          1100       6645\n9            95       5905\n10          240       3675\n11           85       5645\n12           75       2665\n13          165       2375\n14           10       2350\n15           40       2480\n16           20       1760\n17          370       1465\n18           15       2100\n19           30       1975\n20           30       2415\n21           35       1365\n22           10       1305\n23           95       1005\n24           15       1150\n25           30        665\n26           20       1060\n27           10       1210\n28           35       1305\n29           10       1055\n30            0        450\n31           15        605\n32           15        790\n33           35        550\n34           15        470\n35           10        760\n36           10        560\n37           10        675\n38           20        820\n39            0        560\n40           10        360\n41            0        280\n42           10        410\n43            0        340\n44           10        365\n45            0        205\n46           10        210\n47            0        170\n48            0        195\n49           10        125\n50            0        265\n51           10        260\n52            0        175\n53            0        185\n54            0        185\n55            0        465\n56            0        145\n57           15        365\n58            0        145\n59            0        185\n60            0        140\n61            0         85\n62            0        120\n63           10        125\n64            0         40\n65           10        285\n66            0        115\n67            0         25\n\n\nNote:\n\nuse arrange(variable) to go from least to most\nuse arrange(desc(variable)) to go from most to least, arrange(-variable) also works\n\n\n\nslice\nThe slice function will allow us to pick only a subset of the rows based on their numeric order (1st through last).\nFor example, if I want a list of the 10 most commonly spoken aboriginal languages.\n\naboriginal_lang %&gt;% \n  arrange(desc(mother_tongue)) %&gt;% \n1  slice(1:10)\n\n\n1\n\nOnly include the first 10 rows of the dataset\n\n\n\n\n               category          language mother_tongue most_at_home\n1  Aboriginal languages      Cree, n.o.s.         64050        37950\n2  Aboriginal languages         Inuktitut         35210        29230\n3  Aboriginal languages           Ojibway         17885         6175\n4  Aboriginal languages          Oji-Cree         12855         7905\n5  Aboriginal languages              Dene         10700         7710\n6  Aboriginal languages Montagnais (Innu)         10235         8585\n7  Aboriginal languages           Mi'kmaq          6690         3565\n8  Aboriginal languages         Atikamekw          6150         5465\n9  Aboriginal languages       Plains Cree          3065         1345\n10 Aboriginal languages            Stoney          3025         1950\n   most_at_work lang_known\n1          7800      86115\n2          8795      40620\n3           765      28580\n4          1080      15605\n5           770      13060\n6          2055      11445\n7           915       9025\n8          1100       6645\n9            95       5905\n10          240       3675\n\n\n\n\nmutate\nmutate() creates new columns that are functions of existing variables.\n\n\n\nArtwork by @allisonhorst\n\n\nFor example, if I want to create a new column called mother_tongue_K which represents the number of people who speak the language their mother tongue in thousands. You may want to save this new dataset over top of the original dataset so you could use this new column in the future.\n\naboriginal_lang &lt;- aboriginal_lang %&gt;% \n1  mutate(mother_tongue_K = mother_tongue/1000)\n\n\n1\n\nCreates a new column called mother_tongue_K calculated by taking the mother_tongue column and dividing it by 1000.\n\n\n\n\nThis can be useful for unit conversions. It also be useful for making new calculations based on existing data (for example, price and number of square feet could be used to calculate price per square foot).\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "courses/stat0118/118_B_wrangling_homework.html",
    "href": "courses/stat0118/118_B_wrangling_homework.html",
    "title": "STAT 118: Homework B",
    "section": "",
    "text": "Code\n#LOAD PACKAGES\nlibrary(tidyverse)\n\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.3     ‚úî readr     2.1.4\n‚úî forcats   1.0.0     ‚úî stringr   1.5.0\n‚úî ggplot2   3.4.3     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.2     ‚úî tidyr     1.3.0\n‚úî purrr     1.0.2     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nThis assignment concerns the gapminder dataset which is available in the gapminder package.\nFirst, Download gapminder from the menu at the right. You only need to do this once. Once it has been download, you need to call it using the code below.\n\n\nCode\n# LOAD DATA SET\nlibrary(gapminder)\ndata(gapminder) \n\n\nIf you want to view this data, click on the word gapminder in your environment and it should open up\n\n\n\n\n\n\nTip\n\n\n\nThere are often many different ways to get to the right answer on this assignment! I don‚Äôt care how you get the answer. I care that you are clearly explaining how you got your answer ‚Äì either by showing any code you used or explaining in words how you got to the answer you did.\n\n\n\n\n\n\n\n\nTip\n\n\n\nIn the problems below, I have not given you any blank R chunks. If you wish to use some R code to answer the problem, you can add your own R chunk ‚Äì either by typing it directly OR going to Code ‚Äì&gt; Insert Chunk in the top menu.\n\n\n\n1.\nHow many rows and columns does this dataset have?\n\n\n2.\nWhat are the names of the 6 columns?\n\n\n3.\nCreate a dataset called gapminder2002 which only contains information for each of the countries in 2002.\n\n\n4.\nIf you instead try to choose the subset with year equal to 2005, something will go wrong. Try it and explain what happens and why.\n\n\n5.\nPrint out the row of data corresponding to the US in 2002.\n\n\n6.\nIn the above problem, you would have put quotes around United States but not around 2002. Explain why.\n\n\n7.\nWhich country had a higher life expectancy in 1977: Japan or Ireland? Note there are many different possible correct ways of solving this. You just need to find one\n\n\n8.\nWhat is the lowest life expectancy in the gapminder dataset? Which country and year does it correspond to?\n\n\n9.\nFor the year 2002, print out a list of the top 10 countries with the highest life expectancy. They should be ordered from highest life expectancy to 10th highest life expectancy. You should only display the countries name and life expectancy (and no other data).\n\n\n\n\n Back to top"
  },
  {
    "objectID": "courses/stat0118/118_K_Maps1_notes_emw.html",
    "href": "courses/stat0118/118_K_Maps1_notes_emw.html",
    "title": "Cloropleth Maps with maps and sf",
    "section": "",
    "text": "Before we get started, some context:"
  },
  {
    "objectID": "courses/stat0118/118_K_Maps1_notes_emw.html#what-about-subsetting-the-data",
    "href": "courses/stat0118/118_K_Maps1_notes_emw.html#what-about-subsetting-the-data",
    "title": "Cloropleth Maps with maps and sf",
    "section": "What about subsetting the data?",
    "text": "What about subsetting the data?\n\n#Subset to get Italy\nitaly &lt;- map_data(\"world\", region =\"Italy\")\n\n#Subset to get USA\nusa &lt;- map_data(\"world\", region =\"USA\")"
  },
  {
    "objectID": "courses/stat0118/118_K_Maps1_notes_emw.html#what-if-aspect-ratio-is-not-maintained",
    "href": "courses/stat0118/118_K_Maps1_notes_emw.html#what-if-aspect-ratio-is-not-maintained",
    "title": "Cloropleth Maps with maps and sf",
    "section": "What if aspect ratio is not maintained?",
    "text": "What if aspect ratio is not maintained?\n\n# ASPECT RATIO NOT MAINTAINED\nggplot(italy, aes(long, lat)) + \n  geom_polygon(aes(group=group)) + \n  theme_light() +\n  ggtitle(\"Italy - Aspect Ratio Not Maintained (not good)\")\n\n\n\n\n\n# ASPECT RATIO MAINTAINED\nggplot(italy, aes(long, lat)) + \n  geom_polygon(aes(group=group)) + \n  coord_quickmap()  +\n  theme_light() +\n  ggtitle(\"Italy - Aspect Ratio Maintained (better)\")"
  },
  {
    "objectID": "courses/stat0118/118_K_Maps1_notes_emw.html#usa-with-states",
    "href": "courses/stat0118/118_K_Maps1_notes_emw.html#usa-with-states",
    "title": "Cloropleth Maps with maps and sf",
    "section": "USA with states",
    "text": "USA with states\n\n#Load Data from maps\nusa_states &lt;- map_data(\"state\")\n\n#Plot of USA with state borders\nggplot(usa_states, aes(long, lat)) +\ngeom_polygon(aes(group=group)) +\ncoord_quickmap()"
  },
  {
    "objectID": "courses/stat0118/118_K_Maps1_notes_emw.html#how-to-customize-colors",
    "href": "courses/stat0118/118_K_Maps1_notes_emw.html#how-to-customize-colors",
    "title": "Cloropleth Maps with maps and sf",
    "section": "How to customize colors?",
    "text": "How to customize colors?\n\nggplot(usa_states, aes(long, lat)) +\ngeom_polygon(aes(group=group), fill =\"#75816b\", color =\"#292c26\") +\ncoord_quickmap() +\ntheme_light()"
  },
  {
    "objectID": "courses/stat0118/118_K_Maps1_notes_emw.html#adding-labels",
    "href": "courses/stat0118/118_K_Maps1_notes_emw.html#adding-labels",
    "title": "Cloropleth Maps with maps and sf",
    "section": "Adding labels",
    "text": "Adding labels\n\nggplot(nc) + \n  geom_sf() + \n  aes(fill = BIR74) +\n  ggtitle(\"North Carolina, Birth Rates in 1974\") +\n  scale_fill_gradientn(colors = brewer.pal(8, \"Spectral\") ) +  #customize colors\n  theme_light() +\n  geom_sf_text(data = nc[nc$BIR74 &gt;15000,], aes(label = NAME), fontface=\"bold\")"
  },
  {
    "objectID": "courses/stat0118/118_A_Intro_notes_emw.html",
    "href": "courses/stat0118/118_A_Intro_notes_emw.html",
    "title": "Markdown Formatting & R Chunks",
    "section": "",
    "text": "Markdown Syntax\nOutput\n\n\n\n\n*italics*\nitalics\n\n\n**bold**\nbold\n\n\n***bold italics***\nbold italics\n\n\n- chai tea\n- green tea\n- earl grey tea\n\nchai tea\ngreen tea\nearl grey tea\n\n\n\n[this is the text that will display](www.google.com)\nthis is the text that will display\n\n\n![a caption here](jellyfish.jpg)\n |\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nA comprehensive list of markdown syntax can be found at https://quarto.org/docs/authoring/markdown-basics.html."
  },
  {
    "objectID": "courses/stat0118/118_A_Intro_notes_emw.html#centered-and-large-equations",
    "href": "courses/stat0118/118_A_Intro_notes_emw.html#centered-and-large-equations",
    "title": "Markdown Formatting & R Chunks",
    "section": "Centered and large equations",
    "text": "Centered and large equations\nType in the plain text section:\n$$y=\\frac{x^2}{SE(x^2)} $$\nDisplays as:\n\\[y=\\frac{x^2}{SE(x^2)} \\]\nHint: Some people like to use the visual editor to insert equations"
  },
  {
    "objectID": "courses/stat0118/118_A_Intro_notes_emw.html#inline-equations",
    "href": "courses/stat0118/118_A_Intro_notes_emw.html#inline-equations",
    "title": "Markdown Formatting & R Chunks",
    "section": "Inline equations",
    "text": "Inline equations\nType in the plain text section:\nWe take and calculate the standard error $SE(x_1)$.\nDisplays as:\nWe take and calculate the standard error \\(SE(x_1)\\)."
  },
  {
    "objectID": "courses/stat0118/118_A_Intro_notes_emw.html#inline-code",
    "href": "courses/stat0118/118_A_Intro_notes_emw.html#inline-code",
    "title": "Markdown Formatting & R Chunks",
    "section": "Inline code",
    "text": "Inline code\nType in the plain text section:\nThis is a sentence. The value of x is `r x`\nDisplays as:\nThis is a sentence. The value of x is 11."
  },
  {
    "objectID": "courses/stat0118/118_H_forcats_notes_emw.html",
    "href": "courses/stat0118/118_H_forcats_notes_emw.html",
    "title": "categorical data using forcats",
    "section": "",
    "text": "The R package forcats is designed to make working with categorical variables easier and more efficient. It provides a set of functions that allow you to manipulate and analyze categorical data with ease. In this lesson, we‚Äôll cover the basics of the forcats package and some of its most useful functions."
  },
  {
    "objectID": "courses/stat0118/118_H_forcats_notes_emw.html#categorical-variables",
    "href": "courses/stat0118/118_H_forcats_notes_emw.html#categorical-variables",
    "title": "categorical data using forcats",
    "section": "Categorical Variables",
    "text": "Categorical Variables\nLet‚Äôs review what categorical data is. Categorical data is a type of data that consists of categories or labels.\nExamples of categorical data include:\n\nColors (red, blue, green, etc.)\nTypes of vehicles (sedan, SUV, truck)\nEducational degrees (high school, college, graduate school)\n\nCategorical data can be further divided into two types: nominal and ordinal. Nominal data consists of categories that have no inherent order, while ordinal data consists of categories that have a natural order. For example, educational degrees are ordinal data because they can be ordered from least to most advanced."
  },
  {
    "objectID": "courses/stat0118/118_H_forcats_notes_emw.html#mpg-data",
    "href": "courses/stat0118/118_H_forcats_notes_emw.html#mpg-data",
    "title": "categorical data using forcats",
    "section": "mpg Data",
    "text": "mpg Data\nWe will play with different functions in the forcats packages using the mpg dataset from earlier in the semester.\n\nlibrary(forcats)\nlibrary(tidyverse)\ndata(\"mpg\")\n\nRecall our side-by-side boxplot:\n\nmpg %&gt;% \n  ggplot(aes(x=class, y=hwy)) +\n  geom_boxplot()"
  },
  {
    "objectID": "courses/stat0118/118_H_forcats_notes_emw.html#reordering-factor-levels",
    "href": "courses/stat0118/118_H_forcats_notes_emw.html#reordering-factor-levels",
    "title": "categorical data using forcats",
    "section": "Reordering Factor Levels",
    "text": "Reordering Factor Levels\nOne of the most useful functions is fct_relevel(), which allows you to reorder the levels of a factor. This can be useful when you want to change the default ordering of the levels or when you want to group certain levels together.\nIs class a factor?\n\nmpg$class %&gt;% \n  is.factor()\n\n[1] FALSE\n\n\nLet‚Äôs make it a factor!\n\nmpg$class &lt;- mpg$class %&gt;% \n  as.factor()\n\nmpg$class %&gt;% \n  is.factor()\n\n[1] TRUE\n\n\nLet‚Äôs check the levels and their current ordering!\n\nmpg$class %&gt;% \n  levels()\n\n[1] \"2seater\"    \"compact\"    \"midsize\"    \"minivan\"    \"pickup\"    \n[6] \"subcompact\" \"suv\"       \n\n\nTo reorder the levels:\n\nmpg$class &lt;- mpg$class  %&gt;% \n  fct_relevel(\"compact\",\"subcompact\",\"midsize\",\"2seater\",\"minivan\",\"suv\",\"pickup\")\n\nmpg$class %&gt;% \n  levels()\n\n[1] \"compact\"    \"subcompact\" \"midsize\"    \"2seater\"    \"minivan\"   \n[6] \"suv\"        \"pickup\"    \n\n\nLet‚Äôs recreate our side-by-side boxplot now:\n\nmpg %&gt;% \n  ggplot(aes(x=class, y=hwy)) +\n  geom_boxplot()\n\n\n\n\nRather than reordering them manually by typing the order, you could also re-level by some numeric criteria. For example:\n\nmpg$class &lt;- mpg$class %&gt;% \n  fct_reorder(mpg$cty, median)\n\nmpg$class %&gt;% \n  levels()\n\n[1] \"suv\"        \"pickup\"     \"2seater\"    \"minivan\"    \"midsize\"   \n[6] \"subcompact\" \"compact\""
  },
  {
    "objectID": "courses/stat0118/118_H_forcats_notes_emw.html#renaming-factor-levels",
    "href": "courses/stat0118/118_H_forcats_notes_emw.html#renaming-factor-levels",
    "title": "categorical data using forcats",
    "section": "Renaming Factor levels",
    "text": "Renaming Factor levels\nSometimes you might not like the way the levels are named.\n\nmpg$class &lt;- mpg$class  %&gt;% \n  fct_recode(\"two-seater\" = \"2seater\")\n\n## NEW NAME = OLD NAME\n\nmpg$class %&gt;% \n  levels()\n\n[1] \"suv\"        \"pickup\"     \"two-seater\" \"minivan\"    \"midsize\"   \n[6] \"subcompact\" \"compact\"   \n\n#Check out the change in the mpg dataset"
  },
  {
    "objectID": "courses/stat0118/118_H_forcats_notes_emw.html#factor-collapsing",
    "href": "courses/stat0118/118_H_forcats_notes_emw.html#factor-collapsing",
    "title": "categorical data using forcats",
    "section": "Factor Collapsing",
    "text": "Factor Collapsing\nLet‚Äôs say we wanted to create only two categories ‚Äì cars and larger vehicles.\n\nmpg$class_two &lt;- mpg$class %&gt;% \n  fct_collapse(cars = c(\"compact\", \"subcompact\", \"midsize\", \"two-seater\"),\n               big = c(\"pickup\", \"suv\", \"minivan\"))\n\nmpg$class_two %&gt;% \n  levels()\n\n[1] \"big\"  \"cars\""
  },
  {
    "objectID": "courses/stat0118/118_H_forcats_notes_emw.html#lumping-into-an-other-category",
    "href": "courses/stat0118/118_H_forcats_notes_emw.html#lumping-into-an-other-category",
    "title": "categorical data using forcats",
    "section": "Lumping into an other category",
    "text": "Lumping into an other category\n\nfct_lump_min(): lumps levels that appear fewer than min times.\nfct_lump_prop(): lumps levels that appear in fewer than (or equal to) prop * n times.\nfct_lump_n() lumps all levels except for the n most frequent (or least frequent if n &lt; 0)\n\n\ntable(mpg$manufacturer)\n\n\n      audi  chevrolet      dodge       ford      honda    hyundai       jeep \n        18         19         37         25          9         14          8 \nland rover    lincoln    mercury     nissan    pontiac     subaru     toyota \n         4          3          4         13          5         14         34 \nvolkswagen \n        27 \n\n\nLet‚Äôs say we wanted only the manufacturers with at least 15 cars produced. Everything else we want to just be other:\n\nmpg$manufacturer &lt;- mpg$manufacturer %&gt;%   fct_lump_min(15)\n\nmpg$manufacturer %&gt;% \n  levels()\n\n[1] \"audi\"       \"chevrolet\"  \"dodge\"      \"ford\"       \"toyota\"    \n[6] \"volkswagen\" \"Other\""
  },
  {
    "objectID": "courses/stat0118/118_KeyboardShortcuts.html",
    "href": "courses/stat0118/118_KeyboardShortcuts.html",
    "title": "Keyboard Shortcuts",
    "section": "",
    "text": "Action\nWindows/Linux\nMac\n\n\n\n\n\nInsert Chunk\nCtrl + Alt + I\nCmd + Option + I\n\n\n%&gt;%\nInsert pipe operator\nCtrl + Shift + M\nCmd + Shift + M\n\n\n#\nUn/Comment out a line\nCtrl + Shift + C\nCmd + Shift + C\n\n\n\nRun Current line/selection\nCtrl+Enter\nCmd+Return\n\n\n\nRun Current Chunk\nCtrl + Alt + C\nCmd + Option + C\n\n\n\nRun All Chunks Above\nCtrl + Alt + P\nCmd + Option + P\n\n\n\nRender document\nCtrl + Shift + K\nCmd + Shift + K\n\n\n\nUndo\nCtrl + Z\nCmd + Z\n\n\n\nCut\nCtrl+X\nCmd+X\n\n\n\nCopy\nCtrl+C\nCmd+C\n\n\n\nPaste\nCtrl+V\nCmd+V\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "courses/stat0118/118_O_Webscraping_Tables_notes_emw.html",
    "href": "courses/stat0118/118_O_Webscraping_Tables_notes_emw.html",
    "title": "Webscraping Tables with rvest",
    "section": "",
    "text": "#LOAD PACKAGES \nlibrary(tidyverse)\nData doesn‚Äôt just magically appear on your computer you need to get it from somewhere.\nOften times, we download data (.csv files or other) and save it locally on our computer.\nOther times, we download it from R packages (like we did with the gapminder dataset)."
  },
  {
    "objectID": "courses/stat0118/118_O_Webscraping_Tables_notes_emw.html#basics-of-html",
    "href": "courses/stat0118/118_O_Webscraping_Tables_notes_emw.html#basics-of-html",
    "title": "Webscraping Tables with rvest",
    "section": "Basics of HTML",
    "text": "Basics of HTML\n\nHTML stands for Hyper Text Markup Language and is the standard markup language for creating webpages\nHTML code consists of a series of elements\n\n\n\n\n\n\n\nTip\n\n\n\nTypically, an HTML element is defined by a start tag, some content, and an end tag\n&lt;tagname&gt; ...some content here... &lt;/tagname&gt;\n\n\nFor example:\n&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;Page Title&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n\n&lt;h1&gt;My First Heading&lt;/h1&gt;\n&lt;p&gt;My first paragraph.&lt;/p&gt;\n\n&lt;/body&gt;\n&lt;/html&gt;\nThere are many, many different possible tag elements. In this class, it‚Äôs not important that you know the specifics of what each element is. It‚Äôs useful for you to understand the basic structure."
  },
  {
    "objectID": "courses/stat0118/118_O_Webscraping_Tables_notes_emw.html#html-tables",
    "href": "courses/stat0118/118_O_Webscraping_Tables_notes_emw.html#html-tables",
    "title": "Webscraping Tables with rvest",
    "section": "HTML Tables",
    "text": "HTML Tables\nAn HTML table is used to represent data in a structured way\n\n&lt;table&gt; Defines a table\n&lt;th&gt; Defines a header cell in a table\n&lt;tr&gt; Defines a row in a table\n&lt;td&gt; Defines a cell in a table\n\nHere is the HTML code:\n&lt;table&gt;\n  &lt;tr&gt;\n    &lt;th&gt;Name&lt;/th&gt;\n    &lt;th&gt;Birth Year&lt;/th&gt;  \n    &lt;th&gt;Country&lt;/th&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td&gt;Harry Styles&lt;/td&gt;\n    &lt;td&gt;Feb 1, 1994&lt;/td&gt;\n    &lt;td&gt;Britain&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td&gt;Taylor Swift&lt;/td&gt;\n    &lt;td&gt;Dec 13, 1989&lt;/td&gt;\n    &lt;td&gt;USA&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td&gt;Justin Bieber&lt;/td&gt;\n    &lt;td&gt;Mar 1, 1994&lt;/td&gt;\n    &lt;td&gt;Canada&lt;/td&gt;\n  &lt;/tr&gt;\n&lt;/table&gt;\nHere is how the HTML displays in a web browser:\n\n\n\n\nName\n\n\nBirth Year\n\n\nCountry\n\n\n\n\nHarry Styles\n\n\nFeb 1, 1994\n\n\nBritain\n\n\n\n\nTaylor Swift\n\n\nDec 13, 1989\n\n\nUSA\n\n\n\n\nJustin Bieber\n\n\nMar 1, 1994\n\n\nCanada\n\n\n\n\nToday‚Äôs class will focus on scraping data from HTML tables!"
  },
  {
    "objectID": "courses/stat0118/118_O_Webscraping_Tables_notes_emw.html#html-class",
    "href": "courses/stat0118/118_O_Webscraping_Tables_notes_emw.html#html-class",
    "title": "Webscraping Tables with rvest",
    "section": "HTML class",
    "text": "HTML class\nThe class attribute can be added to any HTML element. Often it is used to help customize the styling of the element (among other things).\n&lt;h2 class=\"city\"&gt;Middlebury&lt;/h2&gt;\n&lt;p class=\"city\"&gt;Middlebury is a town in Vermont&lt;/p&gt;\nThis can be particularly useful in web scraping ‚Äì we can ask to scrape particular elements, particular classes, or both!"
  },
  {
    "objectID": "courses/stat0118/118_O_Webscraping_Tables_notes_emw.html#viewing-raw-html-from-a-website",
    "href": "courses/stat0118/118_O_Webscraping_Tables_notes_emw.html#viewing-raw-html-from-a-website",
    "title": "Webscraping Tables with rvest",
    "section": "Viewing Raw HTML from a website",
    "text": "Viewing Raw HTML from a website\nYou can inspect the source code of any webpage by using a web browser like Firefox or Chrome.\n\nOn Firefox, navigate to the ‚ÄúTools‚Äù menu item in the top menu and click on ‚ÄúWeb Developer/Page Source‚Äù. You can also use the shortcut Command + U\nOn Chrome, navigate to the top menu item ‚ÄúView‚Äù and click on ‚ÄúDeveloper/View Source.‚Äù You can also use the keyboard shortcut Option-Command-U. It also can be useful to use the SelectorGadget Extension."
  },
  {
    "objectID": "courses/stat0118/118_O_Webscraping_Tables_notes_emw.html#webscraping-tables-from-wikipedia",
    "href": "courses/stat0118/118_O_Webscraping_Tables_notes_emw.html#webscraping-tables-from-wikipedia",
    "title": "Webscraping Tables with rvest",
    "section": "Webscraping Tables from Wikipedia",
    "text": "Webscraping Tables from Wikipedia\nCheck out the information on the (List of the Most Viewed YouTube Videos on Wikipedia)[https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos]. Suppose we want to scrape this data to use in R.\n\nread_html scrapes the raw html from the webpage as text\nhtml_element (and html_elements) selects particular elements from the HTML code\nhtml_table formats a scraped html table as a tibble (R table)\n\n\nyoutube_videos &lt;- read_html(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\") %&gt;%\n  html_element(\".wikitable\") %&gt;%\n  html_table() \n\nyoutube_videos\n\n# A tibble: 31 √ó 6\n   `Video name`                    Uploader `Views (billions)` Date  Notes ``   \n   &lt;chr&gt;                           &lt;chr&gt;    &lt;chr&gt;              &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n 1 Baby Shark Dance[7]             Pinkfon‚Ä¶ 15.59              June‚Ä¶ \"[A]\" &lt;NA&gt; \n 2 Despacito[10]                   Luis Fo‚Ä¶ 8.65               Janu‚Ä¶ \"[B]\" &lt;NA&gt; \n 3 Wheels on the Bus[18]           Cocomel‚Ä¶ 7.10               May ‚Ä¶ \"\"    &lt;NA&gt; \n 4 Johny Johny Yes Papa[19]        LooLoo ‚Ä¶ 7.01               Octo‚Ä¶ \"\"    &lt;NA&gt; \n 5 Bath Song[20]                   Cocomel‚Ä¶ 7.00               May ‚Ä¶ \"\"    &lt;NA&gt; \n 6 See You Again[21]               Wiz Kha‚Ä¶ 6.56               Apri‚Ä¶ \"[C]\" &lt;NA&gt; \n 7 Shape of You[26]                Ed Shee‚Ä¶ 6.41               Janu‚Ä¶ \"[D]\" &lt;NA&gt; \n 8 Phonics Song with Two Words[29] ChuChu ‚Ä¶ 6.28               Marc‚Ä¶ \"\"    &lt;NA&gt; \n 9 Uptown Funk[30]                 Mark Ro‚Ä¶ 5.48               Nove‚Ä¶ \"\"    &lt;NA&gt; \n10 Gangnam Style[31]               Psy      5.46               July‚Ä¶ \"[E]\" &lt;NA&gt; \n# ‚Ñπ 21 more rows\n\n\n\nWe could have used html_element(\"table\") If we did this, it would have pulled the first &lt;table&gt; from the page.\nWe could have used html_elements(\"table\") If we did this, it would have pulled all the &lt;table&gt; elements from the page.\nIf you want a specific table that isn‚Äôt the first table, scrape all the tables and apply html_table(). Then take that new object of the tables and add [[n]] to get the \\(n^{th}\\) table. For example to call the \\(2^{nd}\\) table,\n\ntables &lt;- html %&gt;% \n  html_elements(\"table\") %&gt;%\n  html_table() \n  \ntables[[2]]\n\nIn this case, we used html_elements(\".wikitable\") I choose to use this because the &lt;table&gt; was also defined with a unique class: &lt;table class=\"wikitable sortable\"&gt;\n\n\n\n\n\n\n\nWarning\n\n\n\nNote that if we are using html_element to call a class, it is important to add a ‚Äú.‚Äù before the class element name. You do not need to do this is you are calling an HTML element (like ‚Äútable‚Äù)"
  },
  {
    "objectID": "courses/stat0118/118_O_Webscraping_Tables_notes_emw.html#cleaning-up-with-janitor",
    "href": "courses/stat0118/118_O_Webscraping_Tables_notes_emw.html#cleaning-up-with-janitor",
    "title": "Webscraping Tables with rvest",
    "section": "Cleaning up with janitor",
    "text": "Cleaning up with janitor\nWeb scraping doesn‚Äôt always format perfectly. Let‚Äôs clean it up!\n\nlibrary(janitor)\n\n\n\n\nArtwork by @allisonhorst\n\n\nClean up the names of the header:\n\nyoutube_videos &lt;- clean_names(youtube_videos)\n\nRemove the last row:\n\n# youtube_videos &lt;- youtube_videos %&gt;% \n#   filter(no != \"As of August 8, 2023\")\n\nFormat the views as a number using as.numeric:\n\nyoutube_videos &lt;- youtube_videos %&gt;% \n  mutate(views_billions = as.numeric(views_billions))\n\nWhat are the top 10 most viewed YouTube Videos?\n\ntop10 &lt;- youtube_videos %&gt;%\n  arrange(desc(views_billions)) %&gt;%\n  slice(1:10)\n\ntop10\n\n# A tibble: 10 √ó 6\n   video_name                      uploader     views_billions date  notes x    \n   &lt;chr&gt;                           &lt;chr&gt;                 &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n 1 Baby Shark Dance[7]             Pinkfong Ba‚Ä¶          15.6  June‚Ä¶ \"[A]\" &lt;NA&gt; \n 2 Despacito[10]                   Luis Fonsi             8.65 Janu‚Ä¶ \"[B]\" &lt;NA&gt; \n 3 Wheels on the Bus[18]           Cocomelon -‚Ä¶           7.1  May ‚Ä¶ \"\"    &lt;NA&gt; \n 4 Johny Johny Yes Papa[19]        LooLoo Kids‚Ä¶           7.01 Octo‚Ä¶ \"\"    &lt;NA&gt; \n 5 Bath Song[20]                   Cocomelon -‚Ä¶           7    May ‚Ä¶ \"\"    &lt;NA&gt; \n 6 See You Again[21]               Wiz Khalifa            6.56 Apri‚Ä¶ \"[C]\" &lt;NA&gt; \n 7 Shape of You[26]                Ed Sheeran             6.41 Janu‚Ä¶ \"[D]\" &lt;NA&gt; \n 8 Phonics Song with Two Words[29] ChuChu TV N‚Ä¶           6.28 Marc‚Ä¶ \"\"    &lt;NA&gt; \n 9 Uptown Funk[30]                 Mark Ronson            5.48 Nove‚Ä¶ \"\"    &lt;NA&gt; \n10 Gangnam Style[31]               Psy                    5.46 July‚Ä¶ \"[E]\" &lt;NA&gt; \n\n\nOnce we have this data, we can make cool plots!\n\ntop10 %&gt;% \n  ggplot( aes(x=views_billions, y=reorder(video_name, views_billions))) +\n    geom_bar(stat=\"identity\") +\n    xlab(\"Views (in billions)\") +\n    ylab(\"Videos\") +\n    ggtitle(\"Top 10 Most Watched YouTube Videos of All Time\") +\n    theme_minimal()\n\n\n\n\n:::callout-tip In this case, the list of the names is still not displaying very neatly. For example, rather than \"Baby Shark Dance\"[6] I might want it to just say Baby Shark Dance.\nWe can use the stringr package to remove symbols and numbers from the video names. We will be talking more about stringr later this semester and it‚Äôs not something I expect you to be able to do at this point in the semester.\n\nlibrary(stringr)\n\ntop10 %&gt;% \n  mutate(video_name=str_replace_all(video_name, \"[^[:alpha:]]\", \" \")) %&gt;% \n  ggplot(aes(x=views_billions, y=reorder(video_name, views_billions))) +\n    geom_bar(stat=\"identity\") +\n    xlab(\"Views (in billions)\") +\n    ylab(\"Videos\") +\n    ggtitle(\"Top 10 Most Watched YouTube Videos of All Time\") +\n    theme_minimal()\n\n\n\n\n\n\n\n\n\n\nExternal Resources\n\n\n\n\nR for Data Science, Webscraping"
  },
  {
    "objectID": "courses/stat0118/118_I_joining_notes_emw.html",
    "href": "courses/stat0118/118_I_joining_notes_emw.html",
    "title": "Joining tables with dplyr",
    "section": "",
    "text": "#LOAD PACKAGES\nlibrary(tidyverse)\n\n#LOAD DATA\nlibrary(nycflights23)\ndata(\"flights\")\n\nnycflights23 contains information about all 435352 flights departing NYC in 2023."
  },
  {
    "objectID": "courses/stat0118/118_I_joining_notes_emw.html#matching-key-variable-names",
    "href": "courses/stat0118/118_I_joining_notes_emw.html#matching-key-variable-names",
    "title": "Joining tables with dplyr",
    "section": "Matching key variable names",
    "text": "Matching key variable names\nSome airline names might be easy to guess (ie. ‚ÄúUA‚Äù is United Airlines), but what airlines have the code ‚ÄúVX‚Äù, ‚ÄúHA‚Äù, and ‚ÄúB6‚Äù? Data on airline codes is provided in a dataset called airlines.\n\n#data(\"airlines\")\n\nWe want to have all this information in one data frame instead of two separate data frames.\nThe variable carrier in flights match the variable carrier in the airlines dataset ‚Äì this is our key variable. In this case, they have the same name, but this doesn‚Äôt necessarily have to be true.\n\nflights_joined &lt;- flights %&gt;% \n  inner_join(airlines, by=\"carrier\")"
  },
  {
    "objectID": "courses/stat0118/118_I_joining_notes_emw.html#different-key-variable-names",
    "href": "courses/stat0118/118_I_joining_notes_emw.html#different-key-variable-names",
    "title": "Joining tables with dplyr",
    "section": "Different key variable names",
    "text": "Different key variable names\nSay instead you are interested in the destinations of all domestic flights departing NYC in 2013, and you ask yourself questions like: ‚ÄúWhat cities are these airports in?‚Äù, or ‚ÄúIs‚ÄùORD‚Äù Orlando?‚Äù\n\ndata(\"airports\")\n\nIn airports the airport code is in faa, whereas in flights the airport codes are in origin and dest.\n\nflights_with_airport_names &lt;- flights %&gt;% \n  inner_join(airports, by = c(\"dest\" = \"faa\"))\n\nLet‚Äôs construct the chain of pipe operators %&gt;% that computes the number of flights from NYC to each destination, but also includes information about each destination airport:\n\nnamed_dests &lt;- flights %&gt;%\n  group_by(dest) %&gt;%\n  summarize(num_flights = n()) %&gt;%\n  arrange(desc(num_flights)) %&gt;%\n  inner_join(airports, by = c(\"dest\" = \"faa\")) %&gt;%\n  rename(airport_name = name)\nnamed_dests\n\n# A tibble: 114 √ó 9\n   dest  num_flights airport_name             lat    lon   alt    tz dst   tzone\n   &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;                  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n 1 BOS         19036 General Edward Lawren‚Ä¶  42.4  -71.0    20    -5 A     Amer‚Ä¶\n 2 ORD         18200 Chicago O'Hare Intern‚Ä¶  42.0  -87.9   672    -6 A     Amer‚Ä¶\n 3 MCO         17756 Orlando International‚Ä¶  28.4  -81.3    96    -5 A     Amer‚Ä¶\n 4 ATL         17570 Hartsfield Jackson At‚Ä¶  33.6  -84.4  1026    -5 A     Amer‚Ä¶\n 5 MIA         16076 Miami International A‚Ä¶  25.8  -80.3     8    -5 A     Amer‚Ä¶\n 6 LAX         15968 Los Angeles Internati‚Ä¶  33.9 -118.    125    -8 A     Amer‚Ä¶\n 7 FLL         14239 Fort Lauderdale Holly‚Ä¶  26.1  -80.2     9    -5 A     Amer‚Ä¶\n 8 CLT         12866 Charlotte Douglas Int‚Ä¶  35.2  -80.9   748    -5 A     Amer‚Ä¶\n 9 DFW         11675 Dallas Fort Worth Int‚Ä¶  32.9  -97.0   607    -6 A     Amer‚Ä¶\n10 SFO         11651 San Francisco Interna‚Ä¶  37.6 -122.     13    -8 A     Amer‚Ä¶\n# ‚Ñπ 104 more rows"
  },
  {
    "objectID": "courses/stat0118/118_I_joining_notes_emw.html#multiple-key-variables",
    "href": "courses/stat0118/118_I_joining_notes_emw.html#multiple-key-variables",
    "title": "Joining tables with dplyr",
    "section": "Multiple Key variables",
    "text": "Multiple Key variables\nIn order to join the flights and weather data frames, we need more than one key variable: year, month, day, hour, and origin. This is because the combination of these 5 variables act to uniquely identify each observational unit in the weather data frame: hourly weather recordings at each of the 3 NYC airports.\n\ndata(\"weather\")\n\n\nflights_weather_joined &lt;- flights %&gt;%\n  inner_join(weather, by = c(\"year\", \"month\", \"day\", \"hour\", \"origin\"))"
  },
  {
    "objectID": "courses/stat0118/118_I_joining_notes_emw.html#why-is-this-useful",
    "href": "courses/stat0118/118_I_joining_notes_emw.html#why-is-this-useful",
    "title": "Joining tables with dplyr",
    "section": "Why is this useful?",
    "text": "Why is this useful?\nUpdating labels:\n\nflights %&gt;% \nggplot(aes(x = carrier, fill = origin)) +\n  geom_bar() + \n  coord_flip()\n\n\n\n#VS\n\nflights %&gt;% \n  inner_join(airports, by = c(\"origin\" = \"faa\")) %&gt;% \n  rename(origin_airport = name) %&gt;% \n  inner_join(airlines, by = c(\"carrier\")) %&gt;%  \n  rename(carrier_name= name) %&gt;% \nggplot(mapping = aes(x = carrier_name, fill = origin_airport)) +\n  geom_bar() + \n  coord_flip()\n\n\n\n\nExploring relationships between variables in separate tables:\n\nflights_weather_joined %&gt;% \n  filter(dep_delay &gt;0) %&gt;% \n  ggplot(aes(x=temp, y=dep_delay)) +\n  geom_point()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Emily Malcolm-White (she/her)",
    "section": "",
    "text": "Hi there! üëã\nI‚Äôm an educator and student support specialist with a passion for teaching and developing quantitative skills for students from a wide variety of backgrounds. I‚Äôm deeply committed to creating an inclusive and equitable learning environment where all students can thrive.\nAt Middlebury College, I teach a range of courses, including statistics, data science, and mathematics. I also serve as the Interim Director of the Quantitative Center (Q-Center), a new initiative dedicated to supporting Middlebury students in developing quantitative skills.\nEvery year, I co-teach ‚ÄúR by the Sea‚Äù, a hands-on data science workshop for marine ecologists. It‚Äôs a rewarding opportunity to merge data science education with real-world applications in marine ecology.\n\n\n Back to top"
  },
  {
    "objectID": "courses/stat0116/index.html",
    "href": "courses/stat0116/index.html",
    "title": "EMW",
    "section": "",
    "text": "More Coming Soon!"
  },
  {
    "objectID": "courses/stat0116/index.html#stat-116-introduction-to-statistical-science",
    "href": "courses/stat0116/index.html#stat-116-introduction-to-statistical-science",
    "title": "EMW",
    "section": "",
    "text": "More Coming Soon!"
  },
  {
    "objectID": "courses/stat0118/118_gganimate_notes_emw.html",
    "href": "courses/stat0118/118_gganimate_notes_emw.html",
    "title": "Animating plots using gganimate",
    "section": "",
    "text": "Artwork by @allisonhorst\n\n\nComing soon!\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "courses/stat0118/118_P_Webscraping_Text_notes_emw.html",
    "href": "courses/stat0118/118_P_Webscraping_Text_notes_emw.html",
    "title": "Webscraping Text with rvest",
    "section": "",
    "text": "#LOAD PACKAGES \nlibrary(tidyverse)\nlibrary(rvest)"
  },
  {
    "objectID": "courses/stat0118/118_P_Webscraping_Text_notes_emw.html#titles",
    "href": "courses/stat0118/118_P_Webscraping_Text_notes_emw.html#titles",
    "title": "Webscraping Text with rvest",
    "section": "Titles",
    "text": "Titles\nFor example, check out the first few lines of html code for Oppenheimer:\n&lt;h3 class=\"lister-item-header\"&gt;\n        &lt;span class=\"lister-item-index unbold text-primary\"&gt;1.&lt;/span&gt;\n    &lt;a href=\"/title/tt15398776/?ref_=adv_li_tt\"\n&gt;Oppenheimer&lt;/a&gt;\n    &lt;span class=\"lister-item-year text-muted unbold\"&gt;(2023)&lt;/span&gt;\n&lt;/h3&gt;\nIn this case, we want to look for the class lister-item-header AND then pull the text inside the &lt;a&gt; (link) tag.\nhtml_elements(\".lister-item-header a\")\n\n\n\n\n\n\nTip\n\n\n\nIn this case, we want ALL titles so we used html_elements(). If we had only wanted the first title we would have used html_element()\n\n\nScrape IMBD for the titles of the 50 most popular feature films in the first 7 months of 2023.\n\n# title_data &lt;- URL %&gt;%\n#   html_elements(\".lister-item-header a\") %&gt;%\n#   html_text()\n# \n# title_data"
  },
  {
    "objectID": "courses/stat0118/118_P_Webscraping_Text_notes_emw.html#runtime",
    "href": "courses/stat0118/118_P_Webscraping_Text_notes_emw.html#runtime",
    "title": "Webscraping Text with rvest",
    "section": "Runtime",
    "text": "Runtime\nScrape IMBD for the runtime of the 50 most popular feature films so far in 2023.\nCheck out the relevant HTML code for Oppenheimer:\n    &lt;p class=\"text-muted \"&gt;\n            &lt;span class=\"certificate\"&gt;R&lt;/span&gt;\n                 &lt;span class=\"ghost\"&gt;|&lt;/span&gt; \n                 &lt;span class=\"runtime\"&gt;180 min&lt;/span&gt;\n                 &lt;span class=\"ghost\"&gt;|&lt;/span&gt; \n            &lt;span class=\"genre\"&gt;\nBiography, Drama, History            &lt;/span&gt;\n    &lt;/p&gt;\nIn this case, we need to reference the class text-muted AND the class runtime.\n\n# URL %&gt;%\n#   html_nodes(\".text-muted .runtime\") %&gt;%\n#   html_text() \n\nAlternatively, we could have called class text-muted AND the 3rd span, but it‚Äôs easier and likely more accurate to ask for the class runtime in case runtime is missing for some reason.\nMaybe we want to keep the min on the end, but it forces it into being a stringr rather than a number which makes it difficult to sort or filter.\n\nlibrary(readr)\n# need this package for parse_number()\n\n\n\n\nArtwork by @allisonhorst\n\n\n\n# runtime_data &lt;- URL %&gt;%\n#   html_nodes(\".text-muted .runtime\") %&gt;%\n#   html_text() %&gt;%\n#   parse_number() %&gt;% #this picks out only the numbers (and drops characters, in this case, \"mins\")\n#   as.numeric()\n# \n# runtime_data"
  },
  {
    "objectID": "courses/stat0118/118_P_Webscraping_Text_notes_emw.html#ratings",
    "href": "courses/stat0118/118_P_Webscraping_Text_notes_emw.html#ratings",
    "title": "Webscraping Text with rvest",
    "section": "Ratings",
    "text": "Ratings\nScrape IMBD for the ratings of the 50 most popular feature films in the first 7 months of 2023.\nCheck out the relevant HTML code for Oppenheimer:\n    &lt;div class=\"inline-block ratings-imdb-rating\" name=\"ir\" data-value=\"8.6\"&gt;\n        &lt;span class=\"global-sprite rating-star imdb-rating\"&gt;&lt;/span&gt;\n        &lt;strong&gt;8.6&lt;/strong&gt;\n    &lt;/div&gt;\nLet‚Äôs scrape it!\n\n# rating_data &lt;- URL %&gt;%\n#   html_elements(\".ratings-imdb-rating strong\") %&gt;%\n#   html_text() %&gt;%\n#   as.numeric()\n# \n# rating_data\n\n\n\n\n\n\n\nWarning\n\n\n\nNotice that there are only 49 ratings listed, not 50! There is no way to figure out which one is missing besides doing it by hand‚Ä¶\nWhich one is it?\nOnce we figure out which one is it is, we should should add a blank element for the rating for that movie using the append function.\nrating_data &lt;- append(rating_data, values=FALSE, after=11)\n\n\nIt‚Äôs Killers of the Flower Moon (#32)!\n\n#rating_data &lt;- append(rating_data, values=NA, after=31)\n\nNotice how it is the correct length (50) now!"
  },
  {
    "objectID": "courses/stat0118/118_P_Webscraping_Text_notes_emw.html#number-of-votes",
    "href": "courses/stat0118/118_P_Webscraping_Text_notes_emw.html#number-of-votes",
    "title": "Webscraping Text with rvest",
    "section": "Number of Votes",
    "text": "Number of Votes\nScrape IMBD for the number of votes of the 50 most popular feature films in the first 7 months of 2023.\nRelevant code for Oppenheimer:\n        &lt;p class=\"sort-num_votes-visible\"&gt;\n                &lt;span class=\"text-muted\"&gt;Votes:&lt;/span&gt;\n                &lt;span name=\"nv\" data-value=\"391689\"&gt;391,689&lt;/span&gt;\n        &lt;/p&gt;\nLet‚Äôs scrape it!\n\n# votes_data &lt;- URL %&gt;%\n#   html_elements(\".sort-num_votes-visible span:nth-child(2)\") %&gt;%\n#   html_text() %&gt;%\n#   parse_number() %&gt;%\n#   as.numeric()\n# \n# votes_data\n\n\n\n\n\n\n\nWarning\n\n\n\nSame issue as before! We were supposed to have 50 but only got 49. It‚Äôs Killers of the Flower Moon (#32), again!\n\n#votes_data &lt;- append(votes_data, values=NA, after=31)"
  },
  {
    "objectID": "courses/stat0118/118_P_Webscraping_Text_notes_emw.html#metascore",
    "href": "courses/stat0118/118_P_Webscraping_Text_notes_emw.html#metascore",
    "title": "Webscraping Text with rvest",
    "section": "Metascore",
    "text": "Metascore\nScrape IMBD for the number of votes of the 50 most popular feature films in the first 7 months of 2023.\nRelevant code for Oppenheimer:\n            &lt;div class=\"inline-block ratings-metascore\"&gt;\n&lt;span class=\"metascore  favorable\"&gt;88        &lt;/span&gt;\n        Metascore\n            &lt;/div&gt;\nLet‚Äôs scrape it!\n\n# metascore_data &lt;- URL %&gt;%\n#   html_elements(\".metascore\") %&gt;%\n#   html_text() %&gt;%\n#   parse_number() %&gt;%\n#   as.numeric()\n# \n# metascore_data\n\n\n\n\n\n\n\nWarning\n\n\n\nYikes! Now we only have 41 when we should have 50.\nWe could manually go through and figure out which 9 are missing or we could reassess how important the metascore data is to us‚Ä¶"
  },
  {
    "objectID": "courses/stat0118/118_D_kable_notes_emw.html",
    "href": "courses/stat0118/118_D_kable_notes_emw.html",
    "title": "Pretty tables with kableExtra",
    "section": "",
    "text": "#LOAD PACKAGES \nlibrary(tidyverse)\n\n\n#LOAD DATA \nlibrary(palmerpenguins)\ndata(penguins)\n\n#CLEAN UP DATA\npenguins &lt;- penguins %&gt;%\n  drop_na()\n#sometimes this is appropriate. It's questionable here... \n\n\ndefault printing style of a table\nLet‚Äôs consider our table from last class:\n\npenguins %&gt;%\n  group_by(species) %&gt;%\n  summarise(average_bill_lenth = mean(bill_length_mm), \n            average_bill_depth = mean(bill_depth_mm))\n\n# A tibble: 3 √ó 3\n  species   average_bill_lenth average_bill_depth\n  &lt;fct&gt;                  &lt;dbl&gt;              &lt;dbl&gt;\n1 Adelie                  38.8               18.3\n2 Chinstrap               48.8               18.4\n3 Gentoo                  47.6               15.0\n\n\nWhen we knit this up it looks like of ugly‚Ä¶\n\n\nUsing kable to get pretty tables\n\nlibrary(kableExtra)\n\n\npenguins %&gt;%\n  group_by(species) %&gt;%\n  summarise(average_bill_length = mean(bill_length_mm), \n            average_bill_depth = mean(bill_depth_mm)) %&gt;% \n  kbl()\n\n\n\n\nspecies\naverage_bill_length\naverage_bill_depth\n\n\n\n\nAdelie\n38.82397\n18.34726\n\n\nChinstrap\n48.83382\n18.42059\n\n\nGentoo\n47.56807\n14.99664\n\n\n\n\n\n\n#OR \n\ntable1 &lt;- penguins %&gt;%\n  group_by(species) %&gt;%\n  summarise(average_bill_length = mean(bill_length_mm), \n            average_bill_depth = mean(bill_depth_mm))\n\nkbl(table1)\n\n\n\n\nspecies\naverage_bill_length\naverage_bill_depth\n\n\n\n\nAdelie\n38.82397\n18.34726\n\n\nChinstrap\n48.83382\n18.42059\n\n\nGentoo\n47.56807\n14.99664\n\n\n\n\n\n\n\n\n\nOptions in kable\nWe customize the content so it‚Äôs displaying the information more clearly.\n\ntable1 %&gt;%\n  kbl(col.names = c(\"Species\", \"Average Bill Length\", \"Average Bill Depth\"), \n    caption = \"Average Bill Characteristics by Species\", \n    digits = 2)\n\n\nAverage Bill Characteristics by Species\n\n\nSpecies\nAverage Bill Length\nAverage Bill Depth\n\n\n\n\nAdelie\n38.82\n18.35\n\n\nChinstrap\n48.83\n18.42\n\n\nGentoo\n47.57\n15.00\n\n\n\n\n\n\n\nBetter‚Ä¶\n\n\npretty styling\n\ntable1 %&gt;%\n  kbl(col.names = c(\"Species\", \"Average Bill Length\", \"Average Bill Depth\"), \n    caption = \"Average Bill Characteristics by Species\", \n    digits = 2) %&gt;%\n  kable_styling()\n\n\nAverage Bill Characteristics by Species\n\n\nSpecies\nAverage Bill Length\nAverage Bill Depth\n\n\n\n\nAdelie\n38.82\n18.35\n\n\nChinstrap\n48.83\n18.42\n\n\nGentoo\n47.57\n15.00\n\n\n\n\n\n\n\nMany options for customizing the look of the tables ‚Äì more here: https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html\nLet‚Äôs try one‚Ä¶\nLet‚Äôs make each row‚Äôs color correspond to\n\ntable1 %&gt;%\n  kbl(col.names = c(\"Species\", \"Average Bill Length\", \"Average Bill Depth\"), \n    caption = \"Average Bill Characteristics by Species\", \n    digits = 2) %&gt;%\n  kable_paper() %&gt;%\n  column_spec(1, bold=T) %&gt;%\n  row_spec(2, color = \"#c85bcc\") %&gt;%\n  row_spec(3, color = \"#067176\") %&gt;%\n  row_spec(1, color = \"#ff7501\")\n\n\nAverage Bill Characteristics by Species\n\n\nSpecies\nAverage Bill Length\nAverage Bill Depth\n\n\n\n\nAdelie\n38.82\n18.35\n\n\nChinstrap\n48.83\n18.42\n\n\nGentoo\n47.57\n15.00\n\n\n\n\n\n\n\nRStudio hosts a table contest every year!\n\nHere is a link to this year‚Äôs contest https://www.rstudio.com/blog/rstudio-table-contest-2022/\nHere is a link to previous year‚Äôs entries and winners to explore what is possible! https://community.rstudio.com/c/table-gallery/64\n\n\n\n\n\n\n\nTip\n\n\n\nAs a general rule, you should have the content of the table as you‚Äôd like it (the exact columns and rows you want) first and then you can make it pretty using the kableExtra package.\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "courses/stat0118/118_E_ggplot1_notes_emw.html",
    "href": "courses/stat0118/118_E_ggplot1_notes_emw.html",
    "title": "barplots and scatterplots",
    "section": "",
    "text": "ggplot2 is a package built within the tidyverse package for creating awesome graphs!\n\n\n\nArtwork by @allisonhorst\n\n\n\nlibrary(tidyverse)\n\n\n#Import the can_lang dataset \ncan_lang &lt;- read.csv(\"https://raw.githubusercontent.com/ttimbers/canlang/master/inst/extdata/can_lang.csv\")\n\n\nRecall our Top 10 example:\nThis code gave a list of 10 Aboriginal Languages which have the most number of people who speak them as their mother tongue:\n\nten_lang &lt;- can_lang %&gt;% \n  filter(category == \"Aboriginal languages\") %&gt;%\n  arrange(by=desc(mother_tongue)) %&gt;%\n  select(language, mother_tongue) %&gt;%\n  slice(1:10)\n\n\n\nBarplots\nSuppose we wanted to display this information in a barplot instead of in a table. Let‚Äôs take a look at the ggplot syntax:\n\n\n\nCredit: https://github.com/UBC-DSCI/introduction-to-datascience/\n\n\n\nggplot(ten_lang, aes(x = language, y = mother_tongue)) +\n  geom_bar(stat = \"identity\")\n\n\n\n\nIs there any improvements we could make to this graph?\n\n\nTo better view text\n\nggplot(ten_lang, aes(x = language, y = mother_tongue)) +\n  geom_bar(stat = \"identity\") +  \n  coord_flip()\n\n\n\n#OR\n\nggplot(ten_lang, aes(x = mother_tongue, y = language)) +\n  geom_bar(stat = \"identity\") \n\n\n\n\n\n\nLabels, Colors, and Themes\n\nggplot(ten_lang, aes(x = mother_tongue, y = reorder(language, mother_tongue))) +\n  geom_bar(fill=\"lightblue\", stat = \"identity\") + \n  ylab(\"Language\") +\n  xlab(\"Mother Tongue (Number of Canadian Residents)\") + \n  ggtitle(\"Ten Aboriginal Languages Most Often \\n Reported by Canadian Residents \\n as Their Mother Tongue\") + \n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nBarplots are good for displaying one categorical variable and one numeric variable. The number variable could be counts (as above) or they could be averages or totals or maximums or minimums (or many other things!)\n\n\n\n\nggplot: scatterplot with geom_point\n\n\n\n\n\n\nTip\n\n\n\nScatterplots are good for displaying the relationship between two numerical variables.\n\n\nThe mtcars dataset was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973‚Äì74 models). It‚Äôs available inside the ggplot package which is already installed.\n\n#load the data\ndata(mtcars)\n\n\nggplot(mtcars, aes(x=wt, y=mpg)) +\n  geom_point()\n\n\n\n\nNote that you can change the color, shape (pch for plotting character) and size of these points!\n\nQuick update to the dataset\n\n#code to update `mtcars` dataset so that `am` is treated as a factor rather than a continuous numeric variable\nmtcars &lt;- mtcars %&gt;% \n  mutate(am = as.factor(am))\n\n\n\n\nInside aes() or outside aes()?\nWhat is the difference between these two graphs?\n\n#color not in aesthetics\nggplot(mtcars, aes(x=wt, y=mpg)) +\n  geom_point(color=\"red\")\n\n\n\n\n\n#color in aesthetics\nggplot(mtcars, aes(x=wt, y=mpg)) +\n  geom_point(aes(color=am))\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nIf the thing you are trying to change (color, shape, size, etc.) depends on a variable, you should put in inside the aesthetics\nIf the thing you are trying to change (color, shape, size, etc.) should happen for all things, you should not put it inside the aesthetics.\n\n\n\n\n\nCustomizing Colors in Aesthetics\n\n#color in aesthetics\nggplot(mtcars, aes(x=wt, y=mpg)) +\n  geom_point(aes(color=am)) +\n  scale_color_manual(values=c(\"black\", \"orange\"))\n\n\n\n\n\n\nGlobal vs.¬†Local Aesthetics\nGlobal aesthetic mappings apply to all geometries and can be defined when you initially call ggplot(). All the geometries added as layers will default to this mapping. Local aesthetic mappings add additional information or override the default mappings.\n\n#color = am as a global aethetic\nggplot(mtcars, aes(x=wt, y=mpg, color=am)) +\n  geom_point()\n\n\n\n\n\n#color = am as a local aethetic\nggplot(mtcars, aes(x=wt, y=mpg)) +\n  geom_point(aes(color=am))\n\n\n\n\n\n#overwriting color = am as a global aethetic with a local aesthetic\nggplot(mtcars, aes(x=wt, y=mpg, color=am)) +\n  geom_point(color=\"purple\")\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "courses/stat0118/118_L_Maps2_notes_emw.html",
    "href": "courses/stat0118/118_L_Maps2_notes_emw.html",
    "title": "Plotting Points on Maps",
    "section": "",
    "text": "#LOAD PACKAGES \nlibrary(tidyverse)\nlibrary(sf) #this is a package needed so R can work with sf objects\n\n#LOAD DATA\nlibrary(spData) #this packages contains the dataset (with sf objects) that we will be using today\ndata(\"us_states\")"
  },
  {
    "objectID": "courses/stat0118/118_L_Maps2_notes_emw.html#using-openstreet-maps",
    "href": "courses/stat0118/118_L_Maps2_notes_emw.html#using-openstreet-maps",
    "title": "Plotting Points on Maps",
    "section": "Using OpenStreet Maps",
    "text": "Using OpenStreet Maps\nA simple map of Warner Hall:\n\nleaflet() %&gt;%\n  addTiles() %&gt;%  \n  # Add default OpenStreetMap map tiles\n  addMarkers(lng=-73.175, lat=44.010, popup=\"Warner Hall\")\n\n\n\n\n\nA map of all airports in the USA:\n\nleaflet(data=airports_count) %&gt;%\n  addTiles() %&gt;% # Add default OpenStreetMap map tiles\n  addMarkers(lng=~lon, lat=~lat, popup=~faa)\n\n\n\n\n\nor using Circle Markers:\n\nleaflet(data=airports_count) %&gt;%\n  addTiles() %&gt;%# Add default OpenStreetMap map tiles\n  addCircleMarkers(lng=~lon, lat=~lat, popup=~faa, radius = ~count/1000, stroke =FALSE, fillOpacity =0.5)"
  },
  {
    "objectID": "courses/stat0118/index.html",
    "href": "courses/stat0118/index.html",
    "title": "EMW",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "courses/stat0118/118_R_lubridate_notes_emw.html",
    "href": "courses/stat0118/118_R_lubridate_notes_emw.html",
    "title": "Working with dates using lubridate",
    "section": "",
    "text": "Date Formats\nThink of how many different formats you know of to format a date:\n\n2023 07 06\nWed, Jun 7, 2023\n07-06-23\n06-07-23 14:55 ET\n06/07/2023 2:55pm\n\nYikes!\n\n\nDate, Time, and Datetime\nDate/time data are data that conveys information about, you guessed it, date and/or time! There are three relevant data types when we talk about date/time data:\n\nDate - only has the date (e.g.¬†2020-05-15)\nTime - only has the time (e.g.¬†20:45:00)\nDatetime - has both the date and time (e.g.¬†2020-05-15 20:45:00)\n\n\n\nLubridate\n\n\n\nArtwork by @allisonhorst\n\n\n\n#LOAD PACKAGES \nlibrary(tidyverse)\nlibrary(lubridate)\n\n\n\nStandard Date Format\nThe ymd() function transforms data in all kinds of different formats into a standardized date format displaying year, then month, then day.\n\nymd(\"06 02 04\")\n\n[1] \"2006-02-04\"\n\nymd(\"06/02/04\")\n\n[1] \"2006-02-04\"\n\nymd(\"20060204\")  # works as well\n\n[1] \"2006-02-04\"\n\nymd(\"2006 2 4\")\n\n[1] \"2006-02-04\"\n\nymd(060204)  # works with numbers\n\n[1] \"2006-02-04\"\n\n\nmdy() (month day year) and dmy() (day month year) formats also exist.\n\nymd_hms(\"2020-04-01 10:30:13\")\n\n[1] \"2020-04-01 10:30:13 UTC\"\n\nymd_hm(\"2020/04/01 10.30\")\n\n[1] \"2020-04-01 10:30:00 UTC\"\n\n\n\n\nSolar Data\nShoal Marine Lab (SML) is a remote field station located on Appledore Island, Maine jointly operated by Cornell University and the University of New Hampshire. The island is powered primarily by solar power.\n\n#read in Data\npower &lt;- read.csv(\"data/power.csv\")\n\nWhat format is the date in?\n\n\n\n\n\n\nWarning\n\n\n\nWhat happens if we try to make a line plot with the date in this format?\n\npower %&gt;% \n  ggplot(aes(x=Date, y=power_kW)) +\n  geom_line()\n\n\n\n\nYikes!\n\n\nWe need to put it in standardized date format first:\n\npower &lt;- power %&gt;% \n  mutate(Date = mdy_hm(Date))  \n\nStandardized Format helps us to create time series plots very easily!\n\npower %&gt;% \n  ggplot(aes(x=Date, y=power_kW)) +\n  geom_line()\n\n\n\n\n\n\nPicking out information\n\n\n\nArtwork by @allisonhorst\n\n\nSometimes we need to pick out year, month, date so we can filter, sort, etc.\n\npower &lt;- power %&gt;% \n  mutate(Year = year(Date)) %&gt;%   \n  mutate(Month = month(Date)) %&gt;% \n  mutate(Day = day(Date))\n\nSuppose we only want the time series plot for June 1:\n\npower %&gt;% \n  filter(Month == \"6\") %&gt;%\n  filter(Day == \"1\") %&gt;% \n  ggplot(aes(x=Date, y=power_kW)) +\n  geom_line()\n\n\n\n\n\n\nPortal Data\nThe Portal Project is a long-term ecological study being conducted near Portal, AZ. Since 1977, the site has been used to study the interactions among rodents, ants and plants and their respective responses to climate.\n\n#LOAD DATA\nportal_rodent &lt;- read.csv(\"https://github.com/weecology/PortalData/raw/main/Rodents/Portal_rodent.csv\")\n\nUnfortunately, because the information about datetime is divided up into different columns, R does not recognize it as date/time data. What we need to do is combine and convert all of these columns into datetime. To do this, we can use the function make_datetime()\n\nportal_rodent &lt;- portal_rodent %&gt;% \n  mutate(datetime = make_datetime(year, month, day))\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "courses/stat0118/118_G_ggplot3_notes_emw.html",
    "href": "courses/stat0118/118_G_ggplot3_notes_emw.html",
    "title": "plotting numeric data using scales, labels, jitter",
    "section": "",
    "text": "library(tidyverse)\n#Import the can_lang dataset \ncan_lang &lt;- read.csv(\"https://raw.githubusercontent.com/ttimbers/canlang/master/inst/extdata/can_lang.csv\")"
  },
  {
    "objectID": "courses/stat0118/118_G_ggplot3_notes_emw.html#mutate-to-create-new-columns",
    "href": "courses/stat0118/118_G_ggplot3_notes_emw.html#mutate-to-create-new-columns",
    "title": "plotting numeric data using scales, labels, jitter",
    "section": "mutate to create new columns",
    "text": "mutate to create new columns\n\ncan_lang &lt;- can_lang %&gt;%\n  mutate(\n    mother_tongue_percent = (mother_tongue / 35151728) * 100,\n    most_at_home_percent = (most_at_home / 35151728) * 100\n  )"
  },
  {
    "objectID": "courses/stat0118/118_G_ggplot3_notes_emw.html#scatterplot-with-percents-and-colors",
    "href": "courses/stat0118/118_G_ggplot3_notes_emw.html#scatterplot-with-percents-and-colors",
    "title": "plotting numeric data using scales, labels, jitter",
    "section": "Scatterplot with Percents and Colors",
    "text": "Scatterplot with Percents and Colors\n\nggplot(can_lang, aes(x = most_at_home_percent, \n                     y = mother_tongue_percent, \n                     color = category, shape=category)) +\n  geom_point() +\n  xlab(\"Language spoken most at home \\n (percentage of Canadian residents)\") +\n  ylab(\"Mother tongue \\n (percentage of Canadian residents)\") +\n  theme(text = element_text(size = 12),\n        legend.position = \"top\",\n        legend.direction = \"vertical\") +\n  scale_x_log10(labels = comma) +\n  scale_y_log10(labels = comma)"
  },
  {
    "objectID": "courses/stat0118/118_G_ggplot3_notes_emw.html#size-of-labels",
    "href": "courses/stat0118/118_G_ggplot3_notes_emw.html#size-of-labels",
    "title": "plotting numeric data using scales, labels, jitter",
    "section": "Size of labels",
    "text": "Size of labels\n\nggplot(can_lang, aes(x = most_at_home_percent, \n                     y = mother_tongue_percent, \n                     color = category, shape=category)) +\n  geom_point() +\n  xlab(\"Language spoken most at home \\n (percentage of Canadian residents)\") +\n  ylab(\"Mother tongue \\n (percentage of Canadian residents)\") +\n  theme(text = element_text(size = 12),\n        legend.position = \"top\",\n        legend.direction = \"vertical\") +\n  scale_x_log10(labels = comma) +\n  scale_y_log10(labels = comma) + \n  geom_text(aes(label=language), \n              nudge_x = 0.25, \n              nudge_y=0.25, size=3)"
  },
  {
    "objectID": "courses/stat0118/118_G_ggplot3_notes_emw.html#subset-the-labels",
    "href": "courses/stat0118/118_G_ggplot3_notes_emw.html#subset-the-labels",
    "title": "plotting numeric data using scales, labels, jitter",
    "section": "Subset the labels",
    "text": "Subset the labels\nCreate a new column for the labels. Use case_when (or ifelse) to only use the official language names and not to put a label for other language categories.\n\ncan_lang &lt;- can_lang %&gt;% \n  mutate(official_languages = case_when(category == \"Official languages\" ~ language, TRUE ~ NA ))\n\n\nggplot(can_lang, aes(x = most_at_home_percent, \n                     y = mother_tongue_percent, \n                     color = category, shape=category)) +\n  geom_point() +\n  xlab(\"Language spoken most at home \\n (percentage of Canadian residents)\") +\n  ylab(\"Mother tongue \\n (percentage of Canadian residents)\") +\n  theme(text = element_text(size = 12),\n        legend.position = \"top\",\n        legend.direction = \"vertical\") +\n  scale_x_log10(labels = comma) +\n  scale_y_log10(labels = comma) + \n  geom_text(aes(label=official_languages), \n              nudge_x = 0.25, \n              nudge_y=0.25, size = 3)"
  },
  {
    "objectID": "courses/stat0118/118_G_ggplot3_notes_emw.html#using-ggrepel",
    "href": "courses/stat0118/118_G_ggplot3_notes_emw.html#using-ggrepel",
    "title": "plotting numeric data using scales, labels, jitter",
    "section": "Using ggrepel",
    "text": "Using ggrepel\n\nlibrary(ggrepel)\n\n\n\n\nArtwork by @allisonhorst\n\n\n\nggplot(can_lang, aes(x = most_at_home_percent, \n                     y = mother_tongue_percent, \n                     color = category, shape=category)) +\n  geom_point() +\n  xlab(\"Language spoken most at home \\n (percentage of Canadian residents)\") +\n  ylab(\"Mother tongue \\n (percentage of Canadian residents)\") +\n  theme(text = element_text(size = 12),\n        legend.position = \"top\",\n        legend.direction = \"vertical\") +\n  scale_x_log10(labels = comma) +\n  scale_y_log10(labels = comma) + \n  geom_text_repel(aes(label=official_languages), min.segment.length=0, box.padding=1)"
  },
  {
    "objectID": "courses/stat0118/118_B_wrangling_notes.html",
    "href": "courses/stat0118/118_B_wrangling_notes.html",
    "title": "filter, select, arrange, slice, mutate",
    "section": "",
    "text": "Installing and Using Packages\n\nlibrary(tidyverse) \n\nToday we are specifically going to be talking about the package dplyr which is useful to manipulating data sets.\n\n\ncan_lang dataset\nIn this class, we are going to be working with a dataset relating to the languages spoken at home by Canadian residents. Many Indigenous peoples exist in Canada with their own languages and cultures. Sadly, colonization has led to the loss of many of these languages. This data is a subset of data collected during the 2016 census.\n\n\nImporting Data\nWhat is a .csv file?\nHow do we import it into R?\nUse read.csv()! Note that your data file (.csv) needs to be saved in the same folder as your notes template document (.qmd).\n\n#can_lang &lt;- read.csv(\"can_lang.csv\") \n\nAlternatively, you can download it directly from the internet. Github user ttimbers hosts this file to share with the public at the link: https://raw.githubusercontent.com/ttimbers/canlang/master/inst/extdata/can_lang.csv\n\n#can_lang &lt;- read.csv(\"https://raw.githubusercontent.com/ttimbers/canlang/master/inst/extdata/can_lang.csv\") \n\nLet‚Äôs take a look at this data for a minute to see what information has been recorded. In the environment in the top left, if you click on the word can_lang (not the blue play button, the word itself) it will open the object so you can see what is saved inside. # filter\nWe can use the filter function to extract rows from the data that have a particular characteristic.\nFor example, we may be interested in only looking at only the languages in this dataset that are Aboriginal languages.\nOftentimes, we want to take our subset and give it a new name. This takes our subset and assigns it to a new dataset called aboriginal_lang.\nSuppose we want a list of all the languages in Canada that are spoken by less than 100 people as their mother tongue.\nThe logical operators are given below:\n\n\n\nOperator\nDescription\n\n\n\n\n&lt;\nLess than\n\n\n&gt;\nGreater than\n\n\n&lt;=\nLess than or equal to\n\n\n&gt;=\nGreater than or equal to\n\n\n==\nEqual to\n\n\n!=\nNot equal to\n\n\n!x\nNot x\n\n\nx | y\nx OR y\n\n\nx & y\nx AND y\n\n\n\n\n\nselect\nselect is used to extract only certain columns. For example, perhaps we only want to print out a list names of the aboriginal languages (language column).\nWe can combine criteria together as well in one command with multiple pipes:\n\n\narrange\nThe arrange function allows us to order the rows of the data frame by the values of a particular column.\nFor example, arrange all the aboriginal languages in canada by from most to least spoken as mother tongue.\nNote:\n\nuse arrange(variable) to go from least to most\nuse arrange(desc(variable)) to go from most to least, arrange(-variable) also works\n\n\n\nslice\nThe slice function will allow us to pick only a subset of the rows based on their numeric order (1st through last).\nFor example, if I want a list of the 10 most commonly spoken aboriginal languages.\n\n\nmutate\nmutate() creates new columns that are functions of existing variables.\nFor example, if I want to create a new column called mother_tongue_K which represents the number of people who speak the language their mother tongue in thousands. You may want to save this new dataset over top of the original dataset so you could use this new column in the future.\nThis can be useful for unit conversions. It also be useful for making new calculations based on existing data (for example, price and number of square feet could be used to calculate price per square foot).\n\n\n\n\n Back to top"
  },
  {
    "objectID": "courses/stat0118/118_patchwork_notes_emw.html",
    "href": "courses/stat0118/118_patchwork_notes_emw.html",
    "title": "Arranging plots with patchwork",
    "section": "",
    "text": "Artwork by @allisonhorst\n\n\nComing soon!\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "courses/stat0118/118_F_ggplot2_notes_emw.html",
    "href": "courses/stat0118/118_F_ggplot2_notes_emw.html",
    "title": "line graphs, histograms & boxplots",
    "section": "",
    "text": "library(tidyverse)\n\nRecall: The mtcars dataset was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973‚Äì74 models). It‚Äôs available inside the ggplot package which is already installed.\n\n#load the data\ndata(mtcars)\n\n\n#code to update `mtcars` dataset so that `am` is treated as a factor rather than a continuous numeric variable\nmtcars &lt;- mtcars %&gt;% \n  mutate(am = as.factor(am))\n\n\nHistograms\n\n\n\n\n\n\nTip\n\n\n\nHistograms are great for looking at the distributions of numeric variables\n\n\n\nmtcars %&gt;% \n  ggplot(aes(x=mpg)) +\n  geom_histogram()\n\n\n\n\nYou can control the bin size with binwidth\n\nmtcars %&gt;% \n  ggplot(aes(x=mpg)) +\n  geom_histogram(binwidth=3)\n\n\n\n\n\n\nBoxplots\n\n\n\n\n\n\nTip\n\n\n\nBoxplots are good for displaying the spread, central tendency, and distribution of one numeric variable.\n\n\n\n\n\nCredit: Michael Galarnyk\n\n\n\nmtcars %&gt;% \n  ggplot(aes(y=mpg)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nSide-by-side boxplots are good for displaying one categorical variable and one numeric variable. One advantage of boxplots over barplots is that they are able to show a bit about the spread and distribution of the numeric variable!\n\n\n\nmtcars %&gt;% \n  ggplot(aes(x=am, y=mpg)) +\n  geom_boxplot()\n\n\n\n\n\n\nLine Graphs\n\n\n\n\n\n\nTip\n\n\n\nLine graphs are great for showing trends with respect to ordinal (ordered variables). Time is used quite commonly.\n\n\nWe consider data on river flow rates collected by volunteers of the Pierce Conservation District in WA.\n\nflow_rates &lt;- read.csv(\"https://www.openintro.org/data/csv/flow_rates.csv\")\n\n\nflow_rates %&gt;% \n  ggplot(aes(x=date, y=flow, group=site, color=site)) + \n  geom_line() + \n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size=7)) +\n  labs(x=\"Date\", y=\"Flow Rate\")\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nWhat happens if we didn‚Äôt have the group= command?\n\nflow_rates %&gt;% \n  ggplot(aes(x=date, y=flow)) + \n  geom_line() + \n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size=7))\n\n\n\n\nYikes!\nIf there is grouping in the data, you need to either: - seperate by group by using the group= command - Merge together (add? average?) the groups using summarize() first before trying to graph\n\n\n\n\nFacet Wrap\nfacet_wrap() is a function in the ggplot2 package that allows you to create a multi-panel plot showing a similar plot over different subsets of the data, usually different values of a categorical variable.\n\n# Example of Facet Wrap with `flow_rates` dataset\nflow_rates %&gt;% \n  ggplot(aes(x=date, y=flow, group=site, color=site)) + \n  geom_line() + \n  facet_wrap(~site) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size=4))\n\n\n\n\nYou can create facets over any categorical variable in the dataset!\n\n#Example of Facet Wrap with `mtcars` dataset\nmtcars %&gt;% \n  mutate(vs=as.factor(vs)) %&gt;% #engine shape 0=v-shaped, 1=manual\n  ggplot(aes(x=vs, y=mpg, fill=am)) +\n  geom_boxplot() + \n  facet_wrap(~am) + \n  theme(legend.position=\"none\") \n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "courses/r-by-the-sea/index.html",
    "href": "courses/r-by-the-sea/index.html",
    "title": "EMW",
    "section": "",
    "text": "I co-teach ‚ÄúR by the Sea‚Äù, a hands-on data science workshop for marine ecologists, with my husband Easton White who runs the Quantitative Marine Ecology Lab at the University of New Hampshire. It‚Äôs a rewarding opportunity to merge data science education with real-world applications in marine ecology.\n\n\n\n\n\nR by the Sea @ Shoals Marine Lab is a two-week boot camp style course designed to help you harness the power of R for ecological and environmental research through project-based learning. Check out the R by the Sea webpage. It contains resources for the most recent iteration of this course.\nFor more information on upcoming offerings and enrolling in the course, check out the Shoals Marine Lab ‚ÄúR by the Sea‚Äù website. The course typically runs in May.\n\n\n\n\n\n\n\nR by the Sea @ Japan 2025 is a one-week boot camp style course taught at the University of Tohoku in Sendai, Japan in January 2025. Check out the R by the Sea Japan webpage for more details."
  },
  {
    "objectID": "courses/r-by-the-sea/index.html#r-by-the-sea",
    "href": "courses/r-by-the-sea/index.html#r-by-the-sea",
    "title": "EMW",
    "section": "",
    "text": "I co-teach ‚ÄúR by the Sea‚Äù, a hands-on data science workshop for marine ecologists, with my husband Easton White who runs the Quantitative Marine Ecology Lab at the University of New Hampshire. It‚Äôs a rewarding opportunity to merge data science education with real-world applications in marine ecology.\n\n\n\n\n\nR by the Sea @ Shoals Marine Lab is a two-week boot camp style course designed to help you harness the power of R for ecological and environmental research through project-based learning. Check out the R by the Sea webpage. It contains resources for the most recent iteration of this course.\nFor more information on upcoming offerings and enrolling in the course, check out the Shoals Marine Lab ‚ÄúR by the Sea‚Äù website. The course typically runs in May.\n\n\n\n\n\n\n\nR by the Sea @ Japan 2025 is a one-week boot camp style course taught at the University of Tohoku in Sendai, Japan in January 2025. Check out the R by the Sea Japan webpage for more details."
  },
  {
    "objectID": "courses/math102/index.html",
    "href": "courses/math102/index.html",
    "title": "EMW",
    "section": "",
    "text": "More Coming Soon!"
  },
  {
    "objectID": "courses/math102/index.html#math-102-logs-exponentials-and-their-applications",
    "href": "courses/math102/index.html#math-102-logs-exponentials-and-their-applications",
    "title": "EMW",
    "section": "",
    "text": "More Coming Soon!"
  }
]